04/06/2021 01:26:55 - ERROR - pytorch_pretrained_bert.tokenization -   Model name 'pt_model/laptop_pt/' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese). We assumed 'pt_model/laptop_pt/' was a path or url but couldn't find any file associated to this path or url.
04/06/2021 01:27:35 - ERROR - pytorch_pretrained_bert.tokenization -   Model name 'pt_model/laptop_pt/' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese). We assumed 'pt_model/laptop_pt/' was a path or url but couldn't find any file associated to this path or url.
04/06/2021 01:45:25 - ERROR - pytorch_pretrained_bert.tokenization -   Model name 'pt_model/laptop_pt/' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese). We assumed 'pt_model/laptop_pt/' was a path or url but couldn't find any file associated to this path or url.
05/12/2021 17:49:55 - INFO - __main__ -   ***** Running training *****
05/12/2021 17:49:55 - INFO - __main__ -     Num examples = 150
05/12/2021 17:49:55 - INFO - __main__ -     Batch size = 4
05/12/2021 17:49:55 - INFO - __main__ -     Num steps = 148
05/12/2021 17:49:55 - INFO - __main__ -   ***** Running validations *****
05/12/2021 17:49:55 - INFO - __main__ -     Num orig examples = 150
05/12/2021 17:49:55 - INFO - __main__ -     Num split examples = 150
05/12/2021 17:49:55 - INFO - __main__ -     Batch size = 4
05/12/2021 17:49:55 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/12/2021 17:49:55 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/12/2021 17:49:57 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/12/2021 17:49:57 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/12/2021 17:50:37 - INFO - __main__ -   validation loss: 47.174596, epoch: 1
05/12/2021 17:50:39 - INFO - __main__ -   ***** Running evaluation *****
05/12/2021 17:50:39 - INFO - __main__ -     Num examples = 150
05/12/2021 17:50:39 - INFO - __main__ -     Batch size = 8
05/12/2021 17:51:25 - INFO - __main__ -   validation loss: 53.224890, epoch: 2
05/12/2021 17:51:27 - INFO - __main__ -   ***** Running evaluation *****
05/12/2021 17:51:27 - INFO - __main__ -     Num examples = 150
05/12/2021 17:51:27 - INFO - __main__ -     Batch size = 8
05/12/2021 17:52:07 - INFO - __main__ -   validation loss: 53.311447, epoch: 3
05/12/2021 17:52:09 - INFO - __main__ -   ***** Running evaluation *****
05/12/2021 17:52:09 - INFO - __main__ -     Num examples = 150
05/12/2021 17:52:09 - INFO - __main__ -     Batch size = 8
05/12/2021 17:52:41 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/12/2021 17:52:41 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/12/2021 17:52:42 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/12/2021 17:52:50 - INFO - __main__ -   validation loss: 54.168640, epoch: 4
05/12/2021 17:52:51 - INFO - __main__ -   ***** Running evaluation *****
05/12/2021 17:52:51 - INFO - __main__ -     Num examples = 150
05/12/2021 17:52:51 - INFO - __main__ -     Batch size = 8
05/12/2021 17:52:56 - INFO - __main__ -   ***** Running evaluation *****
05/12/2021 17:52:56 - INFO - __main__ -     Num examples = 800
05/12/2021 17:52:56 - INFO - __main__ -     Batch size = 8
05/12/2021 17:54:38 - INFO - __main__ -   ***** Running training *****
05/12/2021 17:54:38 - INFO - __main__ -     Num examples = 150
05/12/2021 17:54:38 - INFO - __main__ -     Batch size = 4
05/12/2021 17:54:38 - INFO - __main__ -     Num steps = 148
05/12/2021 17:54:39 - INFO - __main__ -   ***** Running validations *****
05/12/2021 17:54:39 - INFO - __main__ -     Num orig examples = 150
05/12/2021 17:54:39 - INFO - __main__ -     Num split examples = 150
05/12/2021 17:54:39 - INFO - __main__ -     Batch size = 4
05/12/2021 17:54:39 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/12/2021 17:54:39 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/12/2021 17:54:41 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/12/2021 17:54:41 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/12/2021 17:55:43 - INFO - __main__ -   ***** Running training *****
05/12/2021 17:55:43 - INFO - __main__ -     Num examples = 150
05/12/2021 17:55:43 - INFO - __main__ -     Batch size = 4
05/12/2021 17:55:43 - INFO - __main__ -     Num steps = 148
05/12/2021 17:55:43 - INFO - __main__ -   ***** Running validations *****
05/12/2021 17:55:43 - INFO - __main__ -     Num orig examples = 150
05/12/2021 17:55:43 - INFO - __main__ -     Num split examples = 150
05/12/2021 17:55:43 - INFO - __main__ -     Batch size = 4
05/12/2021 17:55:43 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/12/2021 17:55:43 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/12/2021 17:55:45 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/12/2021 17:55:45 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/12/2021 17:56:20 - INFO - __main__ -   validation loss: 69.646373, epoch: 1
05/12/2021 17:56:21 - INFO - __main__ -   ***** Running evaluation *****
05/12/2021 17:56:21 - INFO - __main__ -     Num examples = 150
05/12/2021 17:56:21 - INFO - __main__ -     Batch size = 8
05/12/2021 17:56:57 - INFO - __main__ -   validation loss: 57.629924, epoch: 2
05/12/2021 17:56:59 - INFO - __main__ -   ***** Running evaluation *****
05/12/2021 17:56:59 - INFO - __main__ -     Num examples = 150
05/12/2021 17:56:59 - INFO - __main__ -     Batch size = 8
05/12/2021 17:57:36 - INFO - __main__ -   validation loss: 57.916060, epoch: 3
05/12/2021 17:57:37 - INFO - __main__ -   ***** Running evaluation *****
05/12/2021 17:57:37 - INFO - __main__ -     Num examples = 150
05/12/2021 17:57:37 - INFO - __main__ -     Batch size = 8
05/12/2021 17:58:06 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/12/2021 17:58:06 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/12/2021 17:58:07 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/12/2021 17:58:14 - INFO - __main__ -   validation loss: 58.236596, epoch: 4
05/12/2021 17:58:16 - INFO - __main__ -   ***** Running evaluation *****
05/12/2021 17:58:16 - INFO - __main__ -     Num examples = 150
05/12/2021 17:58:16 - INFO - __main__ -     Batch size = 8
05/12/2021 17:58:20 - INFO - __main__ -   ***** Running evaluation *****
05/12/2021 17:58:20 - INFO - __main__ -     Num examples = 800
05/12/2021 17:58:20 - INFO - __main__ -     Batch size = 8
05/12/2021 18:32:11 - INFO - __main__ -   ***** Running training *****
05/12/2021 18:32:11 - INFO - __main__ -     Num examples = 150
05/12/2021 18:32:11 - INFO - __main__ -     Batch size = 4
05/12/2021 18:32:11 - INFO - __main__ -     Num steps = 148
05/12/2021 18:32:11 - INFO - __main__ -   ***** Running validations *****
05/12/2021 18:32:11 - INFO - __main__ -     Num orig examples = 150
05/12/2021 18:32:11 - INFO - __main__ -     Num split examples = 150
05/12/2021 18:32:11 - INFO - __main__ -     Batch size = 4
05/12/2021 18:32:11 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/12/2021 18:32:11 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/12/2021 18:32:14 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/12/2021 18:32:14 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/12/2021 20:33:46 - INFO - __main__ -   ***** Running training *****
05/12/2021 20:33:46 - INFO - __main__ -     Num examples = 150
05/12/2021 20:33:46 - INFO - __main__ -     Batch size = 4
05/12/2021 20:33:46 - INFO - __main__ -     Num steps = 148
05/12/2021 20:33:46 - INFO - __main__ -   ***** Running validations *****
05/12/2021 20:33:46 - INFO - __main__ -     Num orig examples = 150
05/12/2021 20:33:46 - INFO - __main__ -     Num split examples = 150
05/12/2021 20:33:46 - INFO - __main__ -     Batch size = 4
05/12/2021 20:36:19 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/12/2021 20:36:42 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/12/2021 21:09:56 - INFO - __main__ -   ***** Running training *****
05/12/2021 21:09:56 - INFO - __main__ -     Num examples = 150
05/12/2021 21:09:56 - INFO - __main__ -     Batch size = 4
05/12/2021 21:09:56 - INFO - __main__ -     Num steps = 148
05/12/2021 21:09:56 - INFO - __main__ -   ***** Running validations *****
05/12/2021 21:09:56 - INFO - __main__ -     Num orig examples = 150
05/12/2021 21:09:56 - INFO - __main__ -     Num split examples = 150
05/12/2021 21:09:56 - INFO - __main__ -     Batch size = 4
05/12/2021 21:09:59 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/12/2021 21:09:59 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/12/2021 21:30:46 - INFO - __main__ -   ***** Running training *****
05/12/2021 21:30:46 - INFO - __main__ -     Num examples = 150
05/12/2021 21:30:46 - INFO - __main__ -     Batch size = 4
05/12/2021 21:30:46 - INFO - __main__ -     Num steps = 148
05/12/2021 21:30:46 - INFO - __main__ -   ***** Running validations *****
05/12/2021 21:30:46 - INFO - __main__ -     Num orig examples = 150
05/12/2021 21:30:46 - INFO - __main__ -     Num split examples = 150
05/12/2021 21:30:46 - INFO - __main__ -     Batch size = 4
05/12/2021 21:30:46 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/12/2021 21:30:46 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 02:50:43 - INFO - __main__ -   ***** Running training *****
05/13/2021 02:50:43 - INFO - __main__ -     Num examples = 150
05/13/2021 02:50:43 - INFO - __main__ -     Batch size = 4
05/13/2021 02:50:43 - INFO - __main__ -     Num steps = 148
05/13/2021 02:50:43 - INFO - __main__ -   ***** Running validations *****
05/13/2021 02:50:43 - INFO - __main__ -     Num orig examples = 150
05/13/2021 02:50:43 - INFO - __main__ -     Num split examples = 150
05/13/2021 02:50:43 - INFO - __main__ -     Batch size = 4
05/13/2021 02:50:43 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 02:50:43 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 03:15:10 - INFO - __main__ -   ***** Running training *****
05/13/2021 03:15:10 - INFO - __main__ -     Num examples = 150
05/13/2021 03:15:10 - INFO - __main__ -     Batch size = 4
05/13/2021 03:15:10 - INFO - __main__ -     Num steps = 148
05/13/2021 03:15:10 - INFO - __main__ -   ***** Running validations *****
05/13/2021 03:15:10 - INFO - __main__ -     Num orig examples = 150
05/13/2021 03:15:10 - INFO - __main__ -     Num split examples = 150
05/13/2021 03:15:10 - INFO - __main__ -     Batch size = 4
05/13/2021 03:15:10 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 03:15:10 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 18:53:16 - INFO - __main__ -   ***** Running training *****
05/13/2021 18:53:16 - INFO - __main__ -     Num examples = 150
05/13/2021 18:53:16 - INFO - __main__ -     Batch size = 4
05/13/2021 18:53:16 - INFO - __main__ -     Num steps = 148
05/13/2021 18:53:16 - INFO - __main__ -   ***** Running validations *****
05/13/2021 18:53:16 - INFO - __main__ -     Num orig examples = 150
05/13/2021 18:53:16 - INFO - __main__ -     Num split examples = 150
05/13/2021 18:53:16 - INFO - __main__ -     Batch size = 4
05/13/2021 18:53:16 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 18:53:16 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 18:54:04 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 18:54:04 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 19:07:14 - INFO - __main__ -   ***** Running training *****
05/13/2021 19:07:14 - INFO - __main__ -     Num examples = 150
05/13/2021 19:07:14 - INFO - __main__ -     Batch size = 4
05/13/2021 19:07:14 - INFO - __main__ -     Num steps = 148
05/13/2021 19:07:14 - INFO - __main__ -   ***** Running validations *****
05/13/2021 19:07:14 - INFO - __main__ -     Num orig examples = 150
05/13/2021 19:07:14 - INFO - __main__ -     Num split examples = 150
05/13/2021 19:07:14 - INFO - __main__ -     Batch size = 4
05/13/2021 19:07:14 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 19:07:14 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 19:07:17 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 19:07:17 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 19:22:15 - INFO - __main__ -   ***** Running training *****
05/13/2021 19:22:15 - INFO - __main__ -     Num examples = 150
05/13/2021 19:22:15 - INFO - __main__ -     Batch size = 4
05/13/2021 19:22:15 - INFO - __main__ -     Num steps = 148
05/13/2021 19:22:15 - INFO - __main__ -   ***** Running validations *****
05/13/2021 19:22:15 - INFO - __main__ -     Num orig examples = 150
05/13/2021 19:22:15 - INFO - __main__ -     Num split examples = 150
05/13/2021 19:22:15 - INFO - __main__ -     Batch size = 4
05/13/2021 19:22:15 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 19:22:15 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 19:22:17 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 19:22:17 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 19:34:12 - INFO - __main__ -   ***** Running training *****
05/13/2021 19:34:12 - INFO - __main__ -     Num examples = 150
05/13/2021 19:34:12 - INFO - __main__ -     Batch size = 4
05/13/2021 19:34:12 - INFO - __main__ -     Num steps = 148
05/13/2021 19:34:12 - INFO - __main__ -   ***** Running validations *****
05/13/2021 19:34:12 - INFO - __main__ -     Num orig examples = 150
05/13/2021 19:34:12 - INFO - __main__ -     Num split examples = 150
05/13/2021 19:34:12 - INFO - __main__ -     Batch size = 4
05/13/2021 19:34:12 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 19:34:12 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 19:38:32 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 19:38:32 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 19:45:21 - INFO - __main__ -   ***** Running training *****
05/13/2021 19:45:21 - INFO - __main__ -     Num examples = 150
05/13/2021 19:45:21 - INFO - __main__ -     Batch size = 4
05/13/2021 19:45:21 - INFO - __main__ -     Num steps = 148
05/13/2021 19:45:21 - INFO - __main__ -   ***** Running validations *****
05/13/2021 19:45:21 - INFO - __main__ -     Num orig examples = 150
05/13/2021 19:45:21 - INFO - __main__ -     Num split examples = 150
05/13/2021 19:45:21 - INFO - __main__ -     Batch size = 4
05/13/2021 19:45:21 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 19:45:21 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 19:45:23 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 19:45:23 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:02:54 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:02:54 - INFO - __main__ -     Num examples = 150
05/13/2021 20:02:54 - INFO - __main__ -     Batch size = 4
05/13/2021 20:02:54 - INFO - __main__ -     Num steps = 148
05/13/2021 20:02:54 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:02:54 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:02:54 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:02:54 - INFO - __main__ -     Batch size = 4
05/13/2021 20:02:54 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:02:54 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:02:56 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:02:56 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:07:07 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:07:07 - INFO - __main__ -     Num examples = 150
05/13/2021 20:07:07 - INFO - __main__ -     Batch size = 4
05/13/2021 20:07:07 - INFO - __main__ -     Num steps = 148
05/13/2021 20:07:07 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:07:07 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:07:07 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:07:07 - INFO - __main__ -     Batch size = 4
05/13/2021 20:07:07 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:07:07 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:07:09 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:07:09 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:13:19 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:13:19 - INFO - __main__ -     Num examples = 150
05/13/2021 20:13:19 - INFO - __main__ -     Batch size = 4
05/13/2021 20:13:19 - INFO - __main__ -     Num steps = 148
05/13/2021 20:13:19 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:13:19 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:13:19 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:13:19 - INFO - __main__ -     Batch size = 4
05/13/2021 20:13:19 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:13:19 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:13:22 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:13:22 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:15:09 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:15:09 - INFO - __main__ -     Num examples = 150
05/13/2021 20:15:09 - INFO - __main__ -     Batch size = 4
05/13/2021 20:15:09 - INFO - __main__ -     Num steps = 148
05/13/2021 20:15:09 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:15:09 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:15:09 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:15:09 - INFO - __main__ -     Batch size = 4
05/13/2021 20:15:09 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:15:09 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:15:11 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:15:11 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:15:59 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:15:59 - INFO - __main__ -     Num examples = 150
05/13/2021 20:15:59 - INFO - __main__ -     Batch size = 4
05/13/2021 20:15:59 - INFO - __main__ -     Num steps = 148
05/13/2021 20:15:59 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:15:59 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:15:59 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:15:59 - INFO - __main__ -     Batch size = 4
05/13/2021 20:15:59 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:15:59 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:16:01 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:16:01 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:20:05 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:20:05 - INFO - __main__ -     Num examples = 150
05/13/2021 20:20:05 - INFO - __main__ -     Batch size = 4
05/13/2021 20:20:05 - INFO - __main__ -     Num steps = 148
05/13/2021 20:20:05 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:20:05 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:20:05 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:20:05 - INFO - __main__ -     Batch size = 4
05/13/2021 20:20:05 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:20:05 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:25:39 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:25:39 - INFO - __main__ -     Num examples = 150
05/13/2021 20:25:39 - INFO - __main__ -     Batch size = 4
05/13/2021 20:25:39 - INFO - __main__ -     Num steps = 148
05/13/2021 20:25:39 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:25:39 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:25:39 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:25:39 - INFO - __main__ -     Batch size = 4
05/13/2021 20:25:39 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:25:39 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:25:41 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:25:41 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:31:09 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:31:09 - INFO - __main__ -     Num examples = 150
05/13/2021 20:31:09 - INFO - __main__ -     Batch size = 4
05/13/2021 20:31:09 - INFO - __main__ -     Num steps = 148
05/13/2021 20:31:09 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:31:09 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:31:09 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:31:09 - INFO - __main__ -     Batch size = 4
05/13/2021 20:31:09 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:31:09 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:31:11 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:31:11 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:35:09 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:35:09 - INFO - __main__ -     Num examples = 150
05/13/2021 20:35:09 - INFO - __main__ -     Batch size = 4
05/13/2021 20:35:09 - INFO - __main__ -     Num steps = 148
05/13/2021 20:35:09 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:35:09 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:35:09 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:35:09 - INFO - __main__ -     Batch size = 4
05/13/2021 20:35:09 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:35:09 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:35:12 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:35:12 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:36:32 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:36:32 - INFO - __main__ -     Num examples = 150
05/13/2021 20:36:32 - INFO - __main__ -     Batch size = 4
05/13/2021 20:36:32 - INFO - __main__ -     Num steps = 148
05/13/2021 20:36:32 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:36:32 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:36:32 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:36:32 - INFO - __main__ -     Batch size = 4
05/13/2021 20:36:32 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:36:32 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:36:34 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:36:34 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:41:07 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:41:07 - INFO - __main__ -     Num examples = 150
05/13/2021 20:41:07 - INFO - __main__ -     Batch size = 4
05/13/2021 20:41:07 - INFO - __main__ -     Num steps = 148
05/13/2021 20:41:07 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:41:07 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:41:07 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:41:07 - INFO - __main__ -     Batch size = 4
05/13/2021 20:41:07 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:41:07 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:41:09 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:41:09 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:41:42 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:41:42 - INFO - __main__ -     Num examples = 150
05/13/2021 20:41:42 - INFO - __main__ -     Batch size = 4
05/13/2021 20:41:42 - INFO - __main__ -     Num steps = 148
05/13/2021 20:41:42 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:41:42 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:41:42 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:41:42 - INFO - __main__ -     Batch size = 4
05/13/2021 20:41:42 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:41:42 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:41:44 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:41:44 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:43:10 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:43:10 - INFO - __main__ -     Num examples = 150
05/13/2021 20:43:10 - INFO - __main__ -     Batch size = 4
05/13/2021 20:43:10 - INFO - __main__ -     Num steps = 148
05/13/2021 20:43:10 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:43:10 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:43:10 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:43:10 - INFO - __main__ -     Batch size = 4
05/13/2021 20:43:10 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:43:10 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:43:13 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:43:13 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:44:35 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:44:35 - INFO - __main__ -     Num examples = 150
05/13/2021 20:44:35 - INFO - __main__ -     Batch size = 4
05/13/2021 20:44:35 - INFO - __main__ -     Num steps = 148
05/13/2021 20:44:35 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:44:35 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:44:35 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:44:35 - INFO - __main__ -     Batch size = 4
05/13/2021 20:44:35 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:44:35 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:49:20 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:49:20 - INFO - __main__ -     Num examples = 150
05/13/2021 20:49:20 - INFO - __main__ -     Batch size = 4
05/13/2021 20:49:20 - INFO - __main__ -     Num steps = 148
05/13/2021 20:49:20 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:49:20 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:49:20 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:49:20 - INFO - __main__ -     Batch size = 4
05/13/2021 20:49:20 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:49:20 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:49:23 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:49:23 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:49:41 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:49:41 - INFO - __main__ -     Num examples = 150
05/13/2021 20:49:41 - INFO - __main__ -     Batch size = 4
05/13/2021 20:49:41 - INFO - __main__ -     Num steps = 148
05/13/2021 20:49:41 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:49:41 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:49:41 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:49:41 - INFO - __main__ -     Batch size = 4
05/13/2021 20:49:41 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:49:41 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:51:15 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:51:15 - INFO - __main__ -     Num examples = 150
05/13/2021 20:51:15 - INFO - __main__ -     Batch size = 4
05/13/2021 20:51:15 - INFO - __main__ -     Num steps = 148
05/13/2021 20:51:15 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:51:15 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:51:15 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:51:15 - INFO - __main__ -     Batch size = 4
05/13/2021 20:51:15 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:51:15 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:51:51 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:51:51 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:52:25 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:52:25 - INFO - __main__ -     Num examples = 150
05/13/2021 20:52:25 - INFO - __main__ -     Batch size = 4
05/13/2021 20:52:25 - INFO - __main__ -     Num steps = 148
05/13/2021 20:52:25 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:52:25 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:52:25 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:52:25 - INFO - __main__ -     Batch size = 4
05/13/2021 20:52:25 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:52:25 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:52:27 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:52:27 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:53:09 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:53:09 - INFO - __main__ -     Num examples = 150
05/13/2021 20:53:09 - INFO - __main__ -     Batch size = 4
05/13/2021 20:53:09 - INFO - __main__ -     Num steps = 148
05/13/2021 20:53:09 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:53:09 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:53:09 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:53:09 - INFO - __main__ -     Batch size = 4
05/13/2021 20:53:09 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:53:09 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:53:11 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:53:11 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:54:26 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:54:26 - INFO - __main__ -     Num examples = 150
05/13/2021 20:54:26 - INFO - __main__ -     Batch size = 4
05/13/2021 20:54:26 - INFO - __main__ -     Num steps = 148
05/13/2021 20:54:26 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:54:26 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:54:26 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:54:26 - INFO - __main__ -     Batch size = 4
05/13/2021 20:54:26 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:54:26 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:54:28 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:54:28 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:57:14 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:57:14 - INFO - __main__ -     Num examples = 150
05/13/2021 20:57:14 - INFO - __main__ -     Batch size = 4
05/13/2021 20:57:14 - INFO - __main__ -     Num steps = 148
05/13/2021 20:57:14 - INFO - __main__ -   ***** Running validations *****
05/13/2021 20:57:14 - INFO - __main__ -     Num orig examples = 150
05/13/2021 20:57:14 - INFO - __main__ -     Num split examples = 150
05/13/2021 20:57:14 - INFO - __main__ -     Batch size = 4
05/13/2021 20:57:14 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 20:57:14 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 20:57:17 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 20:57:17 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 20:59:35 - INFO - __main__ -   ***** Running training *****
05/13/2021 20:59:35 - INFO - __main__ -     Num examples = 150
05/13/2021 20:59:35 - INFO - __main__ -     Batch size = 4
05/13/2021 20:59:35 - INFO - __main__ -     Num steps = 148
05/13/2021 21:00:36 - INFO - __main__ -   ***** Running training *****
05/13/2021 21:00:36 - INFO - __main__ -     Num examples = 150
05/13/2021 21:00:36 - INFO - __main__ -     Batch size = 4
05/13/2021 21:00:36 - INFO - __main__ -     Num steps = 148
05/13/2021 21:01:17 - INFO - __main__ -   ***** Running validations *****
05/13/2021 21:01:17 - INFO - __main__ -     Num orig examples = 150
05/13/2021 21:01:18 - INFO - __main__ -     Num split examples = 150
05/13/2021 21:01:18 - INFO - __main__ -     Batch size = 4
05/13/2021 21:01:24 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 21:01:24 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 21:01:26 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 21:01:26 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 21:05:05 - INFO - __main__ -   ***** Running training *****
05/13/2021 21:05:05 - INFO - __main__ -     Num examples = 150
05/13/2021 21:05:05 - INFO - __main__ -     Batch size = 4
05/13/2021 21:05:05 - INFO - __main__ -     Num steps = 148
05/13/2021 21:05:05 - INFO - __main__ -   ***** Running validations *****
05/13/2021 21:05:05 - INFO - __main__ -     Num orig examples = 150
05/13/2021 21:05:05 - INFO - __main__ -     Num split examples = 150
05/13/2021 21:05:05 - INFO - __main__ -     Batch size = 4
05/13/2021 21:05:05 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 21:05:05 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 21:05:07 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 21:05:07 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 21:06:36 - INFO - __main__ -   ***** Running training *****
05/13/2021 21:06:36 - INFO - __main__ -     Num examples = 150
05/13/2021 21:06:36 - INFO - __main__ -     Batch size = 4
05/13/2021 21:06:36 - INFO - __main__ -     Num steps = 148
05/13/2021 21:07:39 - INFO - __main__ -   ***** Running training *****
05/13/2021 21:07:39 - INFO - __main__ -     Num examples = 150
05/13/2021 21:07:39 - INFO - __main__ -     Batch size = 4
05/13/2021 21:07:39 - INFO - __main__ -     Num steps = 148
05/13/2021 21:09:49 - INFO - __main__ -   ***** Running training *****
05/13/2021 21:09:49 - INFO - __main__ -     Num examples = 150
05/13/2021 21:09:49 - INFO - __main__ -     Batch size = 4
05/13/2021 21:09:49 - INFO - __main__ -     Num steps = 148
05/13/2021 21:13:09 - INFO - __main__ -   ***** Running validations *****
05/13/2021 21:13:09 - INFO - __main__ -     Num orig examples = 150
05/13/2021 21:13:09 - INFO - __main__ -     Num split examples = 150
05/13/2021 21:13:09 - INFO - __main__ -     Batch size = 4
05/13/2021 21:13:09 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 21:13:09 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 21:13:11 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 21:13:11 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 21:16:56 - INFO - __main__ -   ***** Running training *****
05/13/2021 21:16:56 - INFO - __main__ -     Num examples = 150
05/13/2021 21:16:56 - INFO - __main__ -     Batch size = 4
05/13/2021 21:16:56 - INFO - __main__ -     Num steps = 148
05/13/2021 21:16:56 - INFO - __main__ -   ***** Running validations *****
05/13/2021 21:16:56 - INFO - __main__ -     Num orig examples = 150
05/13/2021 21:16:56 - INFO - __main__ -     Num split examples = 150
05/13/2021 21:16:56 - INFO - __main__ -     Batch size = 4
05/13/2021 21:16:56 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 21:16:56 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 21:16:58 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 21:16:58 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 21:20:29 - INFO - __main__ -   ***** Running training *****
05/13/2021 21:20:29 - INFO - __main__ -     Num examples = 150
05/13/2021 21:20:29 - INFO - __main__ -     Batch size = 4
05/13/2021 21:20:29 - INFO - __main__ -     Num steps = 148
05/13/2021 21:20:29 - INFO - __main__ -   ***** Running validations *****
05/13/2021 21:20:29 - INFO - __main__ -     Num orig examples = 150
05/13/2021 21:20:29 - INFO - __main__ -     Num split examples = 150
05/13/2021 21:20:29 - INFO - __main__ -     Batch size = 4
05/13/2021 21:20:29 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 21:20:29 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 21:20:31 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 21:20:31 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 21:25:28 - INFO - __main__ -   ***** Running training *****
05/13/2021 21:25:28 - INFO - __main__ -     Num examples = 150
05/13/2021 21:25:28 - INFO - __main__ -     Batch size = 4
05/13/2021 21:25:28 - INFO - __main__ -     Num steps = 148
05/13/2021 21:25:28 - INFO - __main__ -   ***** Running validations *****
05/13/2021 21:25:28 - INFO - __main__ -     Num orig examples = 150
05/13/2021 21:25:28 - INFO - __main__ -     Num split examples = 150
05/13/2021 21:25:28 - INFO - __main__ -     Batch size = 4
05/13/2021 21:25:28 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 21:25:28 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 21:36:16 - INFO - __main__ -   ***** Running training *****
05/13/2021 21:36:16 - INFO - __main__ -     Num examples = 150
05/13/2021 21:36:16 - INFO - __main__ -     Batch size = 4
05/13/2021 21:36:16 - INFO - __main__ -     Num steps = 148
05/13/2021 21:36:16 - INFO - __main__ -   ***** Running validations *****
05/13/2021 21:36:16 - INFO - __main__ -     Num orig examples = 150
05/13/2021 21:36:16 - INFO - __main__ -     Num split examples = 150
05/13/2021 21:36:16 - INFO - __main__ -     Batch size = 4
05/13/2021 21:36:16 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 21:36:16 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 21:36:19 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 21:36:19 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 21:40:10 - INFO - __main__ -   ***** Running training *****
05/13/2021 21:40:10 - INFO - __main__ -     Num examples = 150
05/13/2021 21:40:10 - INFO - __main__ -     Batch size = 4
05/13/2021 21:40:10 - INFO - __main__ -     Num steps = 148
05/13/2021 21:40:10 - INFO - __main__ -   ***** Running validations *****
05/13/2021 21:40:10 - INFO - __main__ -     Num orig examples = 150
05/13/2021 21:40:10 - INFO - __main__ -     Num split examples = 150
05/13/2021 21:40:10 - INFO - __main__ -     Batch size = 4
05/13/2021 21:40:10 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 21:40:10 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 21:47:07 - INFO - __main__ -   ***** Running training *****
05/13/2021 21:47:07 - INFO - __main__ -     Num examples = 150
05/13/2021 21:47:07 - INFO - __main__ -     Batch size = 4
05/13/2021 21:47:07 - INFO - __main__ -     Num steps = 148
05/13/2021 21:47:07 - INFO - __main__ -   ***** Running validations *****
05/13/2021 21:47:07 - INFO - __main__ -     Num orig examples = 150
05/13/2021 21:47:07 - INFO - __main__ -     Num split examples = 150
05/13/2021 21:47:07 - INFO - __main__ -     Batch size = 4
05/13/2021 21:47:07 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 21:47:07 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 21:49:26 - INFO - __main__ -   ***** Running training *****
05/13/2021 21:49:26 - INFO - __main__ -     Num examples = 150
05/13/2021 21:49:26 - INFO - __main__ -     Batch size = 4
05/13/2021 21:49:26 - INFO - __main__ -     Num steps = 148
05/13/2021 21:49:26 - INFO - __main__ -   ***** Running validations *****
05/13/2021 21:49:26 - INFO - __main__ -     Num orig examples = 150
05/13/2021 21:49:26 - INFO - __main__ -     Num split examples = 150
05/13/2021 21:49:26 - INFO - __main__ -     Batch size = 4
05/13/2021 21:49:26 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 21:49:26 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 21:51:07 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 21:51:07 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 21:56:09 - INFO - __main__ -   ***** Running training *****
05/13/2021 21:56:09 - INFO - __main__ -     Num examples = 150
05/13/2021 21:56:09 - INFO - __main__ -     Batch size = 4
05/13/2021 21:56:09 - INFO - __main__ -     Num steps = 148
05/13/2021 21:56:09 - INFO - __main__ -   ***** Running validations *****
05/13/2021 21:56:09 - INFO - __main__ -     Num orig examples = 150
05/13/2021 21:56:09 - INFO - __main__ -     Num split examples = 150
05/13/2021 21:56:09 - INFO - __main__ -     Batch size = 4
05/13/2021 21:56:09 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 21:56:09 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 21:58:59 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 21:58:59 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 22:01:06 - INFO - __main__ -   ***** Running training *****
05/13/2021 22:01:06 - INFO - __main__ -     Num examples = 150
05/13/2021 22:01:06 - INFO - __main__ -     Batch size = 4
05/13/2021 22:01:06 - INFO - __main__ -     Num steps = 148
05/13/2021 22:01:06 - INFO - __main__ -   ***** Running validations *****
05/13/2021 22:01:06 - INFO - __main__ -     Num orig examples = 150
05/13/2021 22:01:06 - INFO - __main__ -     Num split examples = 150
05/13/2021 22:01:06 - INFO - __main__ -     Batch size = 4
05/13/2021 22:01:06 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 22:01:06 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 22:02:57 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 22:02:57 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 22:09:37 - INFO - __main__ -   ***** Running training *****
05/13/2021 22:09:37 - INFO - __main__ -     Num examples = 150
05/13/2021 22:09:37 - INFO - __main__ -     Batch size = 4
05/13/2021 22:09:37 - INFO - __main__ -     Num steps = 148
05/13/2021 22:09:37 - INFO - __main__ -   ***** Running validations *****
05/13/2021 22:09:37 - INFO - __main__ -     Num orig examples = 150
05/13/2021 22:09:37 - INFO - __main__ -     Num split examples = 150
05/13/2021 22:09:37 - INFO - __main__ -     Batch size = 4
05/13/2021 22:09:37 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 22:09:37 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 22:09:40 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 22:09:40 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 22:10:12 - INFO - __main__ -   ***** Running training *****
05/13/2021 22:10:12 - INFO - __main__ -     Num examples = 150
05/13/2021 22:10:12 - INFO - __main__ -     Batch size = 4
05/13/2021 22:10:12 - INFO - __main__ -     Num steps = 148
05/13/2021 22:10:12 - INFO - __main__ -   ***** Running validations *****
05/13/2021 22:10:12 - INFO - __main__ -     Num orig examples = 150
05/13/2021 22:10:12 - INFO - __main__ -     Num split examples = 150
05/13/2021 22:10:12 - INFO - __main__ -     Batch size = 4
05/13/2021 22:10:12 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 22:10:12 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 22:10:14 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/13/2021 22:10:14 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/13/2021 22:11:03 - INFO - __main__ -   ***** Running training *****
05/13/2021 22:11:03 - INFO - __main__ -     Num examples = 150
05/13/2021 22:11:03 - INFO - __main__ -     Batch size = 4
05/13/2021 22:11:03 - INFO - __main__ -     Num steps = 148
05/13/2021 22:11:03 - INFO - __main__ -   ***** Running validations *****
05/13/2021 22:11:03 - INFO - __main__ -     Num orig examples = 150
05/13/2021 22:11:03 - INFO - __main__ -     Num split examples = 150
05/13/2021 22:11:03 - INFO - __main__ -     Batch size = 4
05/13/2021 22:11:03 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 22:11:03 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 22:11:15 - INFO - __main__ -   ***** Running training *****
05/13/2021 22:11:15 - INFO - __main__ -     Num examples = 150
05/13/2021 22:11:15 - INFO - __main__ -     Batch size = 4
05/13/2021 22:11:15 - INFO - __main__ -     Num steps = 148
05/13/2021 22:11:15 - INFO - __main__ -   ***** Running validations *****
05/13/2021 22:11:15 - INFO - __main__ -     Num orig examples = 150
05/13/2021 22:11:15 - INFO - __main__ -     Num split examples = 150
05/13/2021 22:11:15 - INFO - __main__ -     Batch size = 4
05/13/2021 22:11:15 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 22:11:15 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 22:12:32 - INFO - __main__ -   ***** Running training *****
05/13/2021 22:12:32 - INFO - __main__ -     Num examples = 150
05/13/2021 22:12:32 - INFO - __main__ -     Batch size = 4
05/13/2021 22:12:32 - INFO - __main__ -     Num steps = 148
05/13/2021 22:12:32 - INFO - __main__ -   ***** Running validations *****
05/13/2021 22:12:32 - INFO - __main__ -     Num orig examples = 150
05/13/2021 22:12:32 - INFO - __main__ -     Num split examples = 150
05/13/2021 22:12:32 - INFO - __main__ -     Batch size = 4
05/13/2021 22:12:32 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 22:12:32 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 22:15:58 - INFO - __main__ -   ***** Running training *****
05/13/2021 22:15:58 - INFO - __main__ -     Num examples = 150
05/13/2021 22:15:58 - INFO - __main__ -     Batch size = 4
05/13/2021 22:15:58 - INFO - __main__ -     Num steps = 148
05/13/2021 22:15:58 - INFO - __main__ -   ***** Running validations *****
05/13/2021 22:15:58 - INFO - __main__ -     Num orig examples = 150
05/13/2021 22:15:58 - INFO - __main__ -     Num split examples = 150
05/13/2021 22:15:58 - INFO - __main__ -     Batch size = 4
05/13/2021 22:15:58 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/13/2021 22:15:58 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/13/2021 23:21:53 - INFO - __main__ -   ***** Running training *****
05/13/2021 23:21:53 - INFO - __main__ -     Num examples = 150
05/13/2021 23:21:53 - INFO - __main__ -     Batch size = 4
05/13/2021 23:21:53 - INFO - __main__ -     Num steps = 148
05/13/2021 23:21:53 - INFO - __main__ -   ***** Running validations *****
05/13/2021 23:21:53 - INFO - __main__ -     Num orig examples = 150
05/13/2021 23:21:53 - INFO - __main__ -     Num split examples = 150
05/13/2021 23:21:53 - INFO - __main__ -     Batch size = 4
05/13/2021 23:53:32 - INFO - __main__ -   ***** Running training *****
05/13/2021 23:53:32 - INFO - __main__ -     Num examples = 150
05/13/2021 23:53:32 - INFO - __main__ -     Batch size = 4
05/13/2021 23:53:32 - INFO - __main__ -     Num steps = 148
05/13/2021 23:53:32 - INFO - __main__ -   ***** Running validations *****
05/13/2021 23:53:32 - INFO - __main__ -     Num orig examples = 150
05/13/2021 23:53:32 - INFO - __main__ -     Num split examples = 150
05/13/2021 23:53:32 - INFO - __main__ -     Batch size = 4
05/14/2021 00:41:20 - INFO - __main__ -   ***** Running training *****
05/14/2021 00:41:20 - INFO - __main__ -     Num examples = 150
05/14/2021 00:41:20 - INFO - __main__ -     Batch size = 4
05/14/2021 00:41:20 - INFO - __main__ -     Num steps = 148
05/14/2021 00:41:20 - INFO - __main__ -   ***** Running validations *****
05/14/2021 00:41:20 - INFO - __main__ -     Num orig examples = 150
05/14/2021 00:41:20 - INFO - __main__ -     Num split examples = 150
05/14/2021 00:41:20 - INFO - __main__ -     Batch size = 4
05/14/2021 22:49:29 - INFO - __main__ -   ***** Running training *****
05/14/2021 22:49:29 - INFO - __main__ -     Num examples = 150
05/14/2021 22:49:29 - INFO - __main__ -     Batch size = 4
05/14/2021 22:49:29 - INFO - __main__ -     Num steps = 148
05/14/2021 22:49:29 - INFO - __main__ -   ***** Running validations *****
05/14/2021 22:49:29 - INFO - __main__ -     Num orig examples = 150
05/14/2021 22:49:29 - INFO - __main__ -     Num split examples = 150
05/14/2021 22:49:29 - INFO - __main__ -     Batch size = 4
05/14/2021 23:02:16 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:02:16 - INFO - __main__ -     Num examples = 150
05/14/2021 23:02:16 - INFO - __main__ -     Batch size = 4
05/14/2021 23:02:16 - INFO - __main__ -     Num steps = 148
05/14/2021 23:02:16 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:02:16 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:02:16 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:02:16 - INFO - __main__ -     Batch size = 4
05/14/2021 23:03:13 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:03:13 - INFO - __main__ -     Num examples = 150
05/14/2021 23:03:13 - INFO - __main__ -     Batch size = 4
05/14/2021 23:03:13 - INFO - __main__ -     Num steps = 148
05/14/2021 23:03:13 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:03:13 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:03:13 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:03:13 - INFO - __main__ -     Batch size = 4
05/14/2021 23:03:13 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/14/2021 23:03:13 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/14/2021 23:03:38 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/14/2021 23:03:38 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/14/2021 23:05:24 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:05:24 - INFO - __main__ -     Num examples = 150
05/14/2021 23:05:24 - INFO - __main__ -     Batch size = 4
05/14/2021 23:05:24 - INFO - __main__ -     Num steps = 148
05/14/2021 23:05:24 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:05:24 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:05:24 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:05:24 - INFO - __main__ -     Batch size = 4
05/14/2021 23:10:29 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:10:29 - INFO - __main__ -     Num examples = 150
05/14/2021 23:10:29 - INFO - __main__ -     Batch size = 4
05/14/2021 23:10:29 - INFO - __main__ -     Num steps = 148
05/14/2021 23:10:29 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:10:29 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:10:29 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:10:29 - INFO - __main__ -     Batch size = 4
05/14/2021 23:11:01 - INFO - __main__ -   validation loss: 156.696977, epoch: 1
05/14/2021 23:11:02 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:11:02 - INFO - __main__ -     Num examples = 150
05/14/2021 23:11:02 - INFO - __main__ -     Batch size = 8
05/14/2021 23:11:33 - INFO - __main__ -   validation loss: 103.091997, epoch: 2
05/14/2021 23:11:34 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:11:34 - INFO - __main__ -     Num examples = 150
05/14/2021 23:11:34 - INFO - __main__ -     Batch size = 8
05/14/2021 23:12:04 - INFO - __main__ -   validation loss: 86.765608, epoch: 3
05/14/2021 23:12:06 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:12:06 - INFO - __main__ -     Num examples = 150
05/14/2021 23:12:06 - INFO - __main__ -     Batch size = 8
05/14/2021 23:12:36 - INFO - __main__ -   validation loss: 82.117791, epoch: 4
05/14/2021 23:12:38 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:12:38 - INFO - __main__ -     Num examples = 150
05/14/2021 23:12:38 - INFO - __main__ -     Batch size = 8
05/14/2021 23:12:44 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:12:44 - INFO - __main__ -     Num examples = 800
05/14/2021 23:12:44 - INFO - __main__ -     Batch size = 8
05/14/2021 23:28:57 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:28:57 - INFO - __main__ -     Num examples = 150
05/14/2021 23:28:57 - INFO - __main__ -     Batch size = 4
05/14/2021 23:28:57 - INFO - __main__ -     Num steps = 148
05/14/2021 23:28:57 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:28:57 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:28:57 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:28:57 - INFO - __main__ -     Batch size = 4
05/14/2021 23:30:57 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:30:57 - INFO - __main__ -     Num examples = 150
05/14/2021 23:30:57 - INFO - __main__ -     Batch size = 4
05/14/2021 23:30:57 - INFO - __main__ -     Num steps = 148
05/14/2021 23:30:57 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:30:57 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:30:57 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:30:57 - INFO - __main__ -     Batch size = 4
05/14/2021 23:31:34 - INFO - __main__ -   validation loss: 189.390290, epoch: 1
05/14/2021 23:31:36 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:31:36 - INFO - __main__ -     Num examples = 150
05/14/2021 23:31:36 - INFO - __main__ -     Batch size = 8
05/14/2021 23:32:12 - INFO - __main__ -   validation loss: 131.240553, epoch: 2
05/14/2021 23:32:14 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:32:14 - INFO - __main__ -     Num examples = 150
05/14/2021 23:32:14 - INFO - __main__ -     Batch size = 8
05/14/2021 23:32:51 - INFO - __main__ -   validation loss: 115.752395, epoch: 3
05/14/2021 23:32:52 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:32:52 - INFO - __main__ -     Num examples = 150
05/14/2021 23:32:52 - INFO - __main__ -     Batch size = 8
05/14/2021 23:33:23 - INFO - __main__ -   validation loss: 110.665242, epoch: 4
05/14/2021 23:33:24 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:33:24 - INFO - __main__ -     Num examples = 150
05/14/2021 23:33:24 - INFO - __main__ -     Batch size = 8
05/14/2021 23:33:29 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:33:29 - INFO - __main__ -     Num examples = 800
05/14/2021 23:33:29 - INFO - __main__ -     Batch size = 8
05/14/2021 23:36:18 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:36:18 - INFO - __main__ -     Num examples = 150
05/14/2021 23:36:18 - INFO - __main__ -     Batch size = 4
05/14/2021 23:36:18 - INFO - __main__ -     Num steps = 148
05/14/2021 23:36:18 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:36:18 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:36:18 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:36:18 - INFO - __main__ -     Batch size = 4
05/14/2021 23:36:55 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:36:55 - INFO - __main__ -     Num examples = 150
05/14/2021 23:36:55 - INFO - __main__ -     Batch size = 4
05/14/2021 23:36:55 - INFO - __main__ -     Num steps = 148
05/14/2021 23:36:56 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:36:56 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:36:56 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:36:56 - INFO - __main__ -     Batch size = 4
05/14/2021 23:37:27 - INFO - __main__ -   validation loss: 102.204903, epoch: 1
05/14/2021 23:37:28 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:37:28 - INFO - __main__ -     Num examples = 150
05/14/2021 23:37:28 - INFO - __main__ -     Batch size = 8
05/14/2021 23:37:58 - INFO - __main__ -   validation loss: 62.595024, epoch: 2
05/14/2021 23:37:59 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:37:59 - INFO - __main__ -     Num examples = 150
05/14/2021 23:37:59 - INFO - __main__ -     Batch size = 8
05/14/2021 23:38:29 - INFO - __main__ -   validation loss: 52.680255, epoch: 3
05/14/2021 23:38:30 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:38:30 - INFO - __main__ -     Num examples = 150
05/14/2021 23:38:30 - INFO - __main__ -     Batch size = 8
05/14/2021 23:39:02 - INFO - __main__ -   validation loss: 51.731357, epoch: 4
05/14/2021 23:39:04 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:39:04 - INFO - __main__ -     Num examples = 150
05/14/2021 23:39:04 - INFO - __main__ -     Batch size = 8
05/14/2021 23:39:11 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:39:11 - INFO - __main__ -     Num examples = 800
05/14/2021 23:39:11 - INFO - __main__ -     Batch size = 8
05/14/2021 23:39:34 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:39:34 - INFO - __main__ -     Num examples = 150
05/14/2021 23:39:34 - INFO - __main__ -     Batch size = 4
05/14/2021 23:39:34 - INFO - __main__ -     Num steps = 148
05/14/2021 23:39:34 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:39:34 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:39:34 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:39:34 - INFO - __main__ -     Batch size = 4
05/14/2021 23:39:55 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:39:55 - INFO - __main__ -     Num examples = 150
05/14/2021 23:39:55 - INFO - __main__ -     Batch size = 4
05/14/2021 23:39:55 - INFO - __main__ -     Num steps = 148
05/14/2021 23:39:55 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:39:55 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:39:55 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:39:55 - INFO - __main__ -     Batch size = 4
05/14/2021 23:40:25 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:40:25 - INFO - __main__ -     Num examples = 150
05/14/2021 23:40:25 - INFO - __main__ -     Batch size = 4
05/14/2021 23:40:25 - INFO - __main__ -     Num steps = 148
05/14/2021 23:40:25 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:40:25 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:40:25 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:40:25 - INFO - __main__ -     Batch size = 4
05/14/2021 23:41:07 - INFO - __main__ -   validation loss: 63.388039, epoch: 1
05/14/2021 23:41:09 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:41:09 - INFO - __main__ -     Num examples = 150
05/14/2021 23:41:09 - INFO - __main__ -     Batch size = 8
05/14/2021 23:41:50 - INFO - __main__ -   validation loss: 43.816969, epoch: 2
05/14/2021 23:41:52 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:41:52 - INFO - __main__ -     Num examples = 150
05/14/2021 23:41:52 - INFO - __main__ -     Batch size = 8
05/14/2021 23:42:32 - INFO - __main__ -   validation loss: 59.050470, epoch: 3
05/14/2021 23:42:34 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:42:34 - INFO - __main__ -     Num examples = 150
05/14/2021 23:42:34 - INFO - __main__ -     Batch size = 8
05/14/2021 23:43:06 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/14/2021 23:43:07 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/14/2021 23:43:07 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/14/2021 23:43:15 - INFO - __main__ -   validation loss: 58.951287, epoch: 4
05/14/2021 23:43:17 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:43:17 - INFO - __main__ -     Num examples = 150
05/14/2021 23:43:17 - INFO - __main__ -     Batch size = 8
05/14/2021 23:43:24 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:43:24 - INFO - __main__ -     Num examples = 800
05/14/2021 23:43:24 - INFO - __main__ -     Batch size = 8
05/14/2021 23:44:37 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:44:37 - INFO - __main__ -     Num examples = 150
05/14/2021 23:44:37 - INFO - __main__ -     Batch size = 4
05/14/2021 23:44:37 - INFO - __main__ -     Num steps = 148
05/14/2021 23:44:37 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:44:37 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:44:37 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:44:37 - INFO - __main__ -     Batch size = 4
05/14/2021 23:45:24 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:45:24 - INFO - __main__ -     Num examples = 150
05/14/2021 23:45:24 - INFO - __main__ -     Batch size = 4
05/14/2021 23:45:24 - INFO - __main__ -     Num steps = 148
05/14/2021 23:45:24 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:45:24 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:45:24 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:45:24 - INFO - __main__ -     Batch size = 4
05/14/2021 23:46:10 - INFO - __main__ -   validation loss: 53.600492, epoch: 1
05/14/2021 23:46:12 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:46:12 - INFO - __main__ -     Num examples = 150
05/14/2021 23:46:12 - INFO - __main__ -     Batch size = 8
05/14/2021 23:46:55 - INFO - __main__ -   validation loss: 42.463040, epoch: 2
05/14/2021 23:46:57 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:46:57 - INFO - __main__ -     Num examples = 150
05/14/2021 23:46:57 - INFO - __main__ -     Batch size = 8
05/14/2021 23:47:40 - INFO - __main__ -   validation loss: 58.513491, epoch: 3
05/14/2021 23:47:42 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:47:42 - INFO - __main__ -     Num examples = 150
05/14/2021 23:47:42 - INFO - __main__ -     Batch size = 8
05/14/2021 23:48:16 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/14/2021 23:48:17 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/14/2021 23:48:18 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/14/2021 23:48:27 - INFO - __main__ -   validation loss: 55.157537, epoch: 4
05/14/2021 23:48:28 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:48:28 - INFO - __main__ -     Num examples = 150
05/14/2021 23:48:28 - INFO - __main__ -     Batch size = 8
05/14/2021 23:48:34 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:48:34 - INFO - __main__ -     Num examples = 800
05/14/2021 23:48:34 - INFO - __main__ -     Batch size = 8
05/14/2021 23:52:11 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:52:11 - INFO - __main__ -     Num examples = 150
05/14/2021 23:52:11 - INFO - __main__ -     Batch size = 4
05/14/2021 23:52:11 - INFO - __main__ -     Num steps = 148
05/14/2021 23:52:11 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:52:11 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:52:11 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:52:11 - INFO - __main__ -     Batch size = 4
05/14/2021 23:53:01 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:53:01 - INFO - __main__ -     Num examples = 150
05/14/2021 23:53:01 - INFO - __main__ -     Batch size = 4
05/14/2021 23:53:01 - INFO - __main__ -     Num steps = 148
05/14/2021 23:53:01 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:53:01 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:53:01 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:53:01 - INFO - __main__ -     Batch size = 4
05/14/2021 23:53:47 - INFO - __main__ -   validation loss: 53.600492, epoch: 1
05/14/2021 23:53:49 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:53:49 - INFO - __main__ -     Num examples = 150
05/14/2021 23:53:49 - INFO - __main__ -     Batch size = 8
05/14/2021 23:54:33 - INFO - __main__ -   validation loss: 42.463040, epoch: 2
05/14/2021 23:54:34 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:54:34 - INFO - __main__ -     Num examples = 150
05/14/2021 23:54:34 - INFO - __main__ -     Batch size = 8
05/14/2021 23:55:18 - INFO - __main__ -   validation loss: 58.513491, epoch: 3
05/14/2021 23:55:19 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:55:19 - INFO - __main__ -     Num examples = 150
05/14/2021 23:55:19 - INFO - __main__ -     Batch size = 8
05/14/2021 23:55:54 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/14/2021 23:55:54 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/14/2021 23:55:55 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/14/2021 23:56:04 - INFO - __main__ -   validation loss: 55.157537, epoch: 4
05/14/2021 23:56:05 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:56:05 - INFO - __main__ -     Num examples = 150
05/14/2021 23:56:05 - INFO - __main__ -     Batch size = 8
05/14/2021 23:56:11 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:56:11 - INFO - __main__ -     Num examples = 800
05/14/2021 23:56:11 - INFO - __main__ -     Batch size = 8
05/14/2021 23:57:28 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:57:28 - INFO - __main__ -     Num examples = 150
05/14/2021 23:57:28 - INFO - __main__ -     Batch size = 4
05/14/2021 23:57:28 - INFO - __main__ -     Num steps = 148
05/14/2021 23:57:28 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:57:28 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:57:28 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:57:28 - INFO - __main__ -     Batch size = 4
05/14/2021 23:58:17 - INFO - __main__ -   ***** Running training *****
05/14/2021 23:58:17 - INFO - __main__ -     Num examples = 150
05/14/2021 23:58:17 - INFO - __main__ -     Batch size = 4
05/14/2021 23:58:17 - INFO - __main__ -     Num steps = 148
05/14/2021 23:58:17 - INFO - __main__ -   ***** Running validations *****
05/14/2021 23:58:17 - INFO - __main__ -     Num orig examples = 150
05/14/2021 23:58:17 - INFO - __main__ -     Num split examples = 150
05/14/2021 23:58:17 - INFO - __main__ -     Batch size = 4
05/14/2021 23:59:00 - INFO - __main__ -   validation loss: 63.388039, epoch: 1
05/14/2021 23:59:01 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:59:01 - INFO - __main__ -     Num examples = 150
05/14/2021 23:59:01 - INFO - __main__ -     Batch size = 8
05/14/2021 23:59:47 - INFO - __main__ -   validation loss: 43.816969, epoch: 2
05/14/2021 23:59:49 - INFO - __main__ -   ***** Running evaluation *****
05/14/2021 23:59:49 - INFO - __main__ -     Num examples = 150
05/14/2021 23:59:49 - INFO - __main__ -     Batch size = 8
05/15/2021 00:00:35 - INFO - __main__ -   validation loss: 59.050470, epoch: 3
05/15/2021 00:00:36 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 00:00:36 - INFO - __main__ -     Num examples = 150
05/15/2021 00:00:36 - INFO - __main__ -     Batch size = 8
05/15/2021 00:01:07 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 00:01:08 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 00:01:08 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 00:01:16 - INFO - __main__ -   validation loss: 58.951287, epoch: 4
05/15/2021 00:01:20 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 00:01:20 - INFO - __main__ -     Num examples = 150
05/15/2021 00:01:20 - INFO - __main__ -     Batch size = 8
05/15/2021 00:01:26 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 00:01:26 - INFO - __main__ -     Num examples = 800
05/15/2021 00:01:26 - INFO - __main__ -     Batch size = 8
05/15/2021 00:24:04 - INFO - __main__ -   ***** Running training *****
05/15/2021 00:24:04 - INFO - __main__ -     Num examples = 150
05/15/2021 00:24:04 - INFO - __main__ -     Batch size = 4
05/15/2021 00:24:04 - INFO - __main__ -     Num steps = 148
05/15/2021 00:24:04 - INFO - __main__ -   ***** Running validations *****
05/15/2021 00:24:04 - INFO - __main__ -     Num orig examples = 150
05/15/2021 00:24:04 - INFO - __main__ -     Num split examples = 150
05/15/2021 00:24:04 - INFO - __main__ -     Batch size = 4
05/15/2021 00:25:21 - INFO - __main__ -   ***** Running training *****
05/15/2021 00:25:21 - INFO - __main__ -     Num examples = 150
05/15/2021 00:25:21 - INFO - __main__ -     Batch size = 4
05/15/2021 00:25:21 - INFO - __main__ -     Num steps = 148
05/15/2021 00:25:21 - INFO - __main__ -   ***** Running validations *****
05/15/2021 00:25:21 - INFO - __main__ -     Num orig examples = 150
05/15/2021 00:25:21 - INFO - __main__ -     Num split examples = 150
05/15/2021 00:25:21 - INFO - __main__ -     Batch size = 4
05/15/2021 00:27:44 - INFO - __main__ -   ***** Running training *****
05/15/2021 00:27:44 - INFO - __main__ -     Num examples = 150
05/15/2021 00:27:44 - INFO - __main__ -     Batch size = 4
05/15/2021 00:27:44 - INFO - __main__ -     Num steps = 148
05/15/2021 00:27:44 - INFO - __main__ -   ***** Running validations *****
05/15/2021 00:27:44 - INFO - __main__ -     Num orig examples = 150
05/15/2021 00:27:44 - INFO - __main__ -     Num split examples = 150
05/15/2021 00:27:44 - INFO - __main__ -     Batch size = 4
05/15/2021 00:53:05 - INFO - __main__ -   ***** Running training *****
05/15/2021 00:53:05 - INFO - __main__ -     Num examples = 150
05/15/2021 00:53:05 - INFO - __main__ -     Batch size = 4
05/15/2021 00:53:05 - INFO - __main__ -     Num steps = 148
05/15/2021 00:53:05 - INFO - __main__ -   ***** Running validations *****
05/15/2021 00:53:05 - INFO - __main__ -     Num orig examples = 150
05/15/2021 00:53:05 - INFO - __main__ -     Num split examples = 150
05/15/2021 00:53:05 - INFO - __main__ -     Batch size = 4
05/15/2021 00:54:20 - INFO - __main__ -   validation loss: 93.104842, epoch: 1
05/15/2021 00:54:21 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 00:54:21 - INFO - __main__ -     Num examples = 150
05/15/2021 00:54:21 - INFO - __main__ -     Batch size = 8
05/15/2021 00:54:54 - INFO - __main__ -   validation loss: 64.872403, epoch: 2
05/15/2021 00:54:56 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 00:54:56 - INFO - __main__ -     Num examples = 150
05/15/2021 00:54:56 - INFO - __main__ -     Batch size = 8
05/15/2021 00:55:28 - INFO - __main__ -   validation loss: 56.758955, epoch: 3
05/15/2021 00:55:30 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 00:55:30 - INFO - __main__ -     Num examples = 150
05/15/2021 00:55:30 - INFO - __main__ -     Batch size = 8
05/15/2021 00:56:03 - INFO - __main__ -   validation loss: 53.911399, epoch: 4
05/15/2021 00:56:04 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 00:56:04 - INFO - __main__ -     Num examples = 150
05/15/2021 00:56:04 - INFO - __main__ -     Batch size = 8
05/15/2021 00:56:09 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 00:56:09 - INFO - __main__ -     Num examples = 800
05/15/2021 00:56:09 - INFO - __main__ -     Batch size = 8
05/15/2021 01:09:18 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:09:18 - INFO - __main__ -     Num examples = 150
05/15/2021 01:09:18 - INFO - __main__ -     Batch size = 4
05/15/2021 01:10:38 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:10:38 - INFO - __main__ -     Num examples = 150
05/15/2021 01:10:38 - INFO - __main__ -     Batch size = 4
05/15/2021 01:10:38 - INFO - __main__ -     Num steps = 148
05/15/2021 01:10:38 - INFO - __main__ -   ***** Running validations *****
05/15/2021 01:10:38 - INFO - __main__ -     Num orig examples = 150
05/15/2021 01:10:38 - INFO - __main__ -     Num split examples = 150
05/15/2021 01:10:38 - INFO - __main__ -     Batch size = 4
05/15/2021 01:11:13 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:11:13 - INFO - __main__ -     Num examples = 150
05/15/2021 01:11:13 - INFO - __main__ -     Batch size = 4
05/15/2021 01:11:13 - INFO - __main__ -     Num steps = 148
05/15/2021 01:11:13 - INFO - __main__ -   ***** Running validations *****
05/15/2021 01:11:13 - INFO - __main__ -     Num orig examples = 150
05/15/2021 01:11:13 - INFO - __main__ -     Num split examples = 150
05/15/2021 01:11:13 - INFO - __main__ -     Batch size = 4
05/15/2021 01:11:46 - INFO - __main__ -   validation loss: 93.104842, epoch: 1
05/15/2021 01:11:48 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:11:48 - INFO - __main__ -     Num examples = 150
05/15/2021 01:11:48 - INFO - __main__ -     Batch size = 8
05/15/2021 01:12:20 - INFO - __main__ -   validation loss: 64.872403, epoch: 2
05/15/2021 01:12:22 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:12:22 - INFO - __main__ -     Num examples = 150
05/15/2021 01:12:22 - INFO - __main__ -     Batch size = 8
05/15/2021 01:12:54 - INFO - __main__ -   validation loss: 56.758955, epoch: 3
05/15/2021 01:12:55 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:12:55 - INFO - __main__ -     Num examples = 150
05/15/2021 01:12:55 - INFO - __main__ -     Batch size = 8
05/15/2021 01:13:26 - INFO - __main__ -   validation loss: 53.911399, epoch: 4
05/15/2021 01:13:28 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:13:28 - INFO - __main__ -     Num examples = 150
05/15/2021 01:13:28 - INFO - __main__ -     Batch size = 8
05/15/2021 01:13:33 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:13:33 - INFO - __main__ -     Num examples = 800
05/15/2021 01:13:33 - INFO - __main__ -     Batch size = 8
05/15/2021 01:14:28 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:14:28 - INFO - __main__ -     Num examples = 150
05/15/2021 01:14:28 - INFO - __main__ -     Batch size = 4
05/15/2021 01:14:28 - INFO - __main__ -     Num steps = 148
05/15/2021 01:14:28 - INFO - __main__ -   ***** Running validations *****
05/15/2021 01:14:28 - INFO - __main__ -     Num orig examples = 150
05/15/2021 01:14:28 - INFO - __main__ -     Num split examples = 150
05/15/2021 01:14:28 - INFO - __main__ -     Batch size = 4
05/15/2021 01:14:38 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:14:38 - INFO - __main__ -     Num examples = 150
05/15/2021 01:14:38 - INFO - __main__ -     Batch size = 4
05/15/2021 01:14:38 - INFO - __main__ -     Num steps = 148
05/15/2021 01:14:38 - INFO - __main__ -   ***** Running validations *****
05/15/2021 01:14:38 - INFO - __main__ -     Num orig examples = 150
05/15/2021 01:14:38 - INFO - __main__ -     Num split examples = 150
05/15/2021 01:14:38 - INFO - __main__ -     Batch size = 4
05/15/2021 01:15:31 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:15:31 - INFO - __main__ -     Num examples = 150
05/15/2021 01:15:31 - INFO - __main__ -     Batch size = 4
05/15/2021 01:15:31 - INFO - __main__ -     Num steps = 148
05/15/2021 01:15:31 - INFO - __main__ -   ***** Running validations *****
05/15/2021 01:15:31 - INFO - __main__ -     Num orig examples = 150
05/15/2021 01:15:31 - INFO - __main__ -     Num split examples = 150
05/15/2021 01:15:31 - INFO - __main__ -     Batch size = 4
05/15/2021 01:26:24 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:26:24 - INFO - __main__ -     Num examples = 150
05/15/2021 01:26:24 - INFO - __main__ -     Batch size = 4
05/15/2021 01:26:24 - INFO - __main__ -     Num steps = 148
05/15/2021 01:26:24 - INFO - __main__ -   ***** Running validations *****
05/15/2021 01:26:24 - INFO - __main__ -     Num orig examples = 150
05/15/2021 01:26:24 - INFO - __main__ -     Num split examples = 150
05/15/2021 01:26:24 - INFO - __main__ -     Batch size = 4
05/15/2021 01:27:29 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:27:29 - INFO - __main__ -     Num examples = 150
05/15/2021 01:27:29 - INFO - __main__ -     Batch size = 4
05/15/2021 01:27:29 - INFO - __main__ -     Num steps = 148
05/15/2021 01:27:29 - INFO - __main__ -   ***** Running validations *****
05/15/2021 01:27:29 - INFO - __main__ -     Num orig examples = 150
05/15/2021 01:27:29 - INFO - __main__ -     Num split examples = 150
05/15/2021 01:27:29 - INFO - __main__ -     Batch size = 4
05/15/2021 01:28:09 - INFO - __main__ -   validation loss: 60.777516, epoch: 1
05/15/2021 01:28:11 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:28:11 - INFO - __main__ -     Num examples = 150
05/15/2021 01:28:11 - INFO - __main__ -     Batch size = 8
05/15/2021 01:28:47 - INFO - __main__ -   validation loss: 40.975192, epoch: 2
05/15/2021 01:28:48 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:28:48 - INFO - __main__ -     Num examples = 150
05/15/2021 01:28:48 - INFO - __main__ -     Batch size = 8
05/15/2021 01:29:23 - INFO - __main__ -   validation loss: 58.703387, epoch: 3
05/15/2021 01:29:24 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:29:24 - INFO - __main__ -     Num examples = 150
05/15/2021 01:29:24 - INFO - __main__ -     Batch size = 8
05/15/2021 01:29:50 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 01:29:51 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 01:29:51 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 01:29:58 - INFO - __main__ -   validation loss: 57.287284, epoch: 4
05/15/2021 01:30:00 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:30:00 - INFO - __main__ -     Num examples = 150
05/15/2021 01:30:00 - INFO - __main__ -     Batch size = 8
05/15/2021 01:30:05 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:30:05 - INFO - __main__ -     Num examples = 800
05/15/2021 01:30:05 - INFO - __main__ -     Batch size = 8
05/15/2021 01:31:16 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:31:16 - INFO - __main__ -     Num examples = 150
05/15/2021 01:31:16 - INFO - __main__ -     Batch size = 4
05/15/2021 01:31:16 - INFO - __main__ -     Num steps = 148
05/15/2021 01:31:16 - INFO - __main__ -   ***** Running validations *****
05/15/2021 01:31:16 - INFO - __main__ -     Num orig examples = 150
05/15/2021 01:31:16 - INFO - __main__ -     Num split examples = 150
05/15/2021 01:31:16 - INFO - __main__ -     Batch size = 4
05/15/2021 01:31:56 - INFO - __main__ -   validation loss: 53.600492, epoch: 1
05/15/2021 01:31:57 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:31:57 - INFO - __main__ -     Num examples = 150
05/15/2021 01:31:57 - INFO - __main__ -     Batch size = 8
05/15/2021 01:32:36 - INFO - __main__ -   validation loss: 42.463040, epoch: 2
05/15/2021 01:32:37 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:32:37 - INFO - __main__ -     Num examples = 150
05/15/2021 01:32:37 - INFO - __main__ -     Batch size = 8
05/15/2021 01:33:15 - INFO - __main__ -   validation loss: 58.513491, epoch: 3
05/15/2021 01:33:17 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:33:17 - INFO - __main__ -     Num examples = 150
05/15/2021 01:33:17 - INFO - __main__ -     Batch size = 8
05/15/2021 01:33:33 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:33:33 - INFO - __main__ -     Num examples = 150
05/15/2021 01:33:33 - INFO - __main__ -     Batch size = 4
05/15/2021 01:33:33 - INFO - __main__ -     Num steps = 148
05/15/2021 01:33:33 - INFO - __main__ -   ***** Running validations *****
05/15/2021 01:33:33 - INFO - __main__ -     Num orig examples = 150
05/15/2021 01:33:33 - INFO - __main__ -     Num split examples = 150
05/15/2021 01:33:33 - INFO - __main__ -     Batch size = 4
05/15/2021 01:34:11 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:34:11 - INFO - __main__ -     Num examples = 150
05/15/2021 01:34:11 - INFO - __main__ -     Batch size = 4
05/15/2021 01:34:11 - INFO - __main__ -     Num steps = 148
05/15/2021 01:34:11 - INFO - __main__ -   ***** Running validations *****
05/15/2021 01:34:11 - INFO - __main__ -     Num orig examples = 150
05/15/2021 01:34:11 - INFO - __main__ -     Num split examples = 150
05/15/2021 01:34:11 - INFO - __main__ -     Batch size = 4
05/15/2021 01:34:46 - INFO - __main__ -   validation loss: 62.064708, epoch: 1
05/15/2021 01:34:48 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:34:48 - INFO - __main__ -     Num examples = 150
05/15/2021 01:34:48 - INFO - __main__ -     Batch size = 8
05/15/2021 01:35:22 - INFO - __main__ -   validation loss: 36.642116, epoch: 2
05/15/2021 01:35:24 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:35:24 - INFO - __main__ -     Num examples = 150
05/15/2021 01:35:24 - INFO - __main__ -     Batch size = 8
05/15/2021 01:35:57 - INFO - __main__ -   validation loss: 37.179848, epoch: 3
05/15/2021 01:35:58 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:35:58 - INFO - __main__ -     Num examples = 150
05/15/2021 01:35:58 - INFO - __main__ -     Batch size = 8
05/15/2021 01:36:31 - INFO - __main__ -   validation loss: 36.102463, epoch: 4
05/15/2021 01:36:33 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:36:33 - INFO - __main__ -     Num examples = 150
05/15/2021 01:36:33 - INFO - __main__ -     Batch size = 8
05/15/2021 01:36:39 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:36:39 - INFO - __main__ -     Num examples = 800
05/15/2021 01:36:39 - INFO - __main__ -     Batch size = 8
05/15/2021 01:40:20 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:40:20 - INFO - __main__ -     Num examples = 150
05/15/2021 01:40:20 - INFO - __main__ -     Batch size = 4
05/15/2021 01:40:20 - INFO - __main__ -     Num steps = 148
05/15/2021 01:40:20 - INFO - __main__ -   ***** Running validations *****
05/15/2021 01:40:20 - INFO - __main__ -     Num orig examples = 150
05/15/2021 01:40:20 - INFO - __main__ -     Num split examples = 150
05/15/2021 01:40:20 - INFO - __main__ -     Batch size = 4
05/15/2021 01:40:56 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:40:56 - INFO - __main__ -     Num examples = 150
05/15/2021 01:40:56 - INFO - __main__ -     Batch size = 4
05/15/2021 01:40:56 - INFO - __main__ -     Num steps = 148
05/15/2021 01:40:56 - INFO - __main__ -   ***** Running validations *****
05/15/2021 01:40:56 - INFO - __main__ -     Num orig examples = 150
05/15/2021 01:40:56 - INFO - __main__ -     Num split examples = 150
05/15/2021 01:40:56 - INFO - __main__ -     Batch size = 4
05/15/2021 01:41:31 - INFO - __main__ -   validation loss: 62.064708, epoch: 1
05/15/2021 01:41:32 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:41:32 - INFO - __main__ -     Num examples = 150
05/15/2021 01:41:32 - INFO - __main__ -     Batch size = 8
05/15/2021 01:42:06 - INFO - __main__ -   validation loss: 36.642116, epoch: 2
05/15/2021 01:42:08 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:42:08 - INFO - __main__ -     Num examples = 150
05/15/2021 01:42:08 - INFO - __main__ -     Batch size = 8
05/15/2021 01:42:41 - INFO - __main__ -   validation loss: 37.179848, epoch: 3
05/15/2021 01:42:43 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:42:43 - INFO - __main__ -     Num examples = 150
05/15/2021 01:42:43 - INFO - __main__ -     Batch size = 8
05/15/2021 01:43:13 - INFO - __main__ -   validation loss: 36.102463, epoch: 4
05/15/2021 01:43:14 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:43:14 - INFO - __main__ -     Num examples = 150
05/15/2021 01:43:14 - INFO - __main__ -     Batch size = 8
05/15/2021 01:43:18 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:43:18 - INFO - __main__ -     Num examples = 800
05/15/2021 01:43:18 - INFO - __main__ -     Batch size = 8
05/15/2021 01:47:34 - INFO - __main__ -   ***** Running training *****
05/15/2021 01:47:34 - INFO - __main__ -     Num examples = 150
05/15/2021 01:47:34 - INFO - __main__ -     Batch size = 4
05/15/2021 01:47:34 - INFO - __main__ -     Num steps = 148
05/15/2021 01:47:35 - INFO - __main__ -   ***** Running validations *****
05/15/2021 01:47:35 - INFO - __main__ -     Num orig examples = 150
05/15/2021 01:47:35 - INFO - __main__ -     Num split examples = 150
05/15/2021 01:47:35 - INFO - __main__ -     Batch size = 4
05/15/2021 01:48:14 - INFO - __main__ -   validation loss: 157.825309, epoch: 1
05/15/2021 01:48:15 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 01:48:15 - INFO - __main__ -     Num examples = 150
05/15/2021 01:48:15 - INFO - __main__ -     Batch size = 8
05/15/2021 02:05:35 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:05:35 - INFO - __main__ -     Num examples = 150
05/15/2021 02:05:35 - INFO - __main__ -     Batch size = 4
05/15/2021 02:05:35 - INFO - __main__ -     Num steps = 148
05/15/2021 02:05:35 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:05:35 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:05:35 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:05:35 - INFO - __main__ -     Batch size = 4
05/15/2021 02:06:14 - INFO - __main__ -   validation loss: 62.064708, epoch: 1
05/15/2021 02:06:16 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:06:16 - INFO - __main__ -     Num examples = 150
05/15/2021 02:06:16 - INFO - __main__ -     Batch size = 8
05/15/2021 02:06:54 - INFO - __main__ -   validation loss: 36.642116, epoch: 2
05/15/2021 02:06:55 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:06:55 - INFO - __main__ -     Num examples = 150
05/15/2021 02:06:55 - INFO - __main__ -     Batch size = 8
05/15/2021 02:07:33 - INFO - __main__ -   validation loss: 37.179848, epoch: 3
05/15/2021 02:07:37 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:07:37 - INFO - __main__ -     Num examples = 150
05/15/2021 02:07:37 - INFO - __main__ -     Batch size = 8
05/15/2021 02:08:15 - INFO - __main__ -   validation loss: 36.102463, epoch: 4
05/15/2021 02:08:17 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:08:17 - INFO - __main__ -     Num examples = 150
05/15/2021 02:08:17 - INFO - __main__ -     Batch size = 8
05/15/2021 02:08:25 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:08:25 - INFO - __main__ -     Num examples = 800
05/15/2021 02:08:25 - INFO - __main__ -     Batch size = 8
05/15/2021 02:09:09 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:09:09 - INFO - __main__ -     Num examples = 150
05/15/2021 02:09:09 - INFO - __main__ -     Batch size = 4
05/15/2021 02:09:09 - INFO - __main__ -     Num steps = 148
05/15/2021 02:09:09 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:09:09 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:09:09 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:09:09 - INFO - __main__ -     Batch size = 4
05/15/2021 02:13:22 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:13:22 - INFO - __main__ -     Num examples = 150
05/15/2021 02:13:22 - INFO - __main__ -     Batch size = 4
05/15/2021 02:13:22 - INFO - __main__ -     Num steps = 148
05/15/2021 02:13:23 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:13:23 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:13:23 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:13:23 - INFO - __main__ -     Batch size = 4
05/15/2021 02:15:07 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:15:07 - INFO - __main__ -     Num examples = 150
05/15/2021 02:15:07 - INFO - __main__ -     Batch size = 4
05/15/2021 02:15:07 - INFO - __main__ -     Num steps = 148
05/15/2021 02:15:07 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:15:07 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:15:07 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:15:07 - INFO - __main__ -     Batch size = 4
05/15/2021 02:15:46 - INFO - __main__ -   validation loss: 45.616957, epoch: 1
05/15/2021 02:15:47 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:15:47 - INFO - __main__ -     Num examples = 150
05/15/2021 02:15:47 - INFO - __main__ -     Batch size = 8
05/15/2021 02:16:23 - INFO - __main__ -   validation loss: 55.523298, epoch: 2
05/15/2021 02:16:25 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:16:25 - INFO - __main__ -     Num examples = 150
05/15/2021 02:16:25 - INFO - __main__ -     Batch size = 8
05/15/2021 02:16:59 - INFO - __main__ -   validation loss: 62.436056, epoch: 3
05/15/2021 02:17:01 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:17:01 - INFO - __main__ -     Num examples = 150
05/15/2021 02:17:01 - INFO - __main__ -     Batch size = 8
05/15/2021 02:17:33 - INFO - __main__ -   validation loss: 65.365013, epoch: 4
05/15/2021 02:17:35 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:17:35 - INFO - __main__ -     Num examples = 150
05/15/2021 02:17:35 - INFO - __main__ -     Batch size = 8
05/15/2021 02:17:39 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:17:39 - INFO - __main__ -     Num examples = 800
05/15/2021 02:17:39 - INFO - __main__ -     Batch size = 8
05/15/2021 02:18:51 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:18:51 - INFO - __main__ -     Num examples = 150
05/15/2021 02:18:51 - INFO - __main__ -     Batch size = 4
05/15/2021 02:18:51 - INFO - __main__ -     Num steps = 148
05/15/2021 02:18:51 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:18:51 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:18:51 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:18:51 - INFO - __main__ -     Batch size = 4
05/15/2021 02:19:31 - INFO - __main__ -   validation loss: 41.542546, epoch: 1
05/15/2021 02:19:32 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:19:32 - INFO - __main__ -     Num examples = 150
05/15/2021 02:19:32 - INFO - __main__ -     Batch size = 8
05/15/2021 02:20:14 - INFO - __main__ -   validation loss: 57.261204, epoch: 2
05/15/2021 02:20:15 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:20:15 - INFO - __main__ -     Num examples = 150
05/15/2021 02:20:15 - INFO - __main__ -     Batch size = 8
05/15/2021 02:20:54 - INFO - __main__ -   validation loss: 59.993338, epoch: 3
05/15/2021 02:20:55 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:20:55 - INFO - __main__ -     Num examples = 150
05/15/2021 02:20:55 - INFO - __main__ -     Batch size = 8
05/15/2021 02:21:32 - INFO - __main__ -   validation loss: 62.623767, epoch: 4
05/15/2021 02:21:33 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:21:33 - INFO - __main__ -     Num examples = 150
05/15/2021 02:21:33 - INFO - __main__ -     Batch size = 8
05/15/2021 02:21:40 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:21:40 - INFO - __main__ -     Num examples = 800
05/15/2021 02:21:40 - INFO - __main__ -     Batch size = 8
05/15/2021 02:22:34 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:22:34 - INFO - __main__ -     Num examples = 150
05/15/2021 02:22:34 - INFO - __main__ -     Batch size = 4
05/15/2021 02:22:34 - INFO - __main__ -     Num steps = 148
05/15/2021 02:22:34 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:22:34 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:22:34 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:22:34 - INFO - __main__ -     Batch size = 4
05/15/2021 02:23:11 - INFO - __main__ -   validation loss: 53.493927, epoch: 1
05/15/2021 02:23:13 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:23:13 - INFO - __main__ -     Num examples = 150
05/15/2021 02:23:13 - INFO - __main__ -     Batch size = 8
05/15/2021 02:23:48 - INFO - __main__ -   validation loss: 45.279222, epoch: 2
05/15/2021 02:23:50 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:23:50 - INFO - __main__ -     Num examples = 150
05/15/2021 02:23:50 - INFO - __main__ -     Batch size = 8
05/15/2021 02:24:28 - INFO - __main__ -   validation loss: 79.471870, epoch: 3
05/15/2021 02:24:29 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:24:29 - INFO - __main__ -     Num examples = 150
05/15/2021 02:24:29 - INFO - __main__ -     Batch size = 8
05/15/2021 02:25:03 - INFO - __main__ -   validation loss: 82.727412, epoch: 4
05/15/2021 02:25:05 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:25:05 - INFO - __main__ -     Num examples = 150
05/15/2021 02:25:05 - INFO - __main__ -     Batch size = 8
05/15/2021 02:25:10 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:25:10 - INFO - __main__ -     Num examples = 800
05/15/2021 02:25:10 - INFO - __main__ -     Batch size = 8
05/15/2021 02:28:05 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:28:05 - INFO - __main__ -     Num examples = 150
05/15/2021 02:28:05 - INFO - __main__ -     Batch size = 4
05/15/2021 02:28:05 - INFO - __main__ -     Num steps = 148
05/15/2021 02:28:05 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:28:05 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:28:05 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:28:05 - INFO - __main__ -     Batch size = 4
05/15/2021 02:28:37 - INFO - __main__ -   validation loss: 59.505320, epoch: 1
05/15/2021 02:28:38 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:28:38 - INFO - __main__ -     Num examples = 150
05/15/2021 02:28:38 - INFO - __main__ -     Batch size = 8
05/15/2021 02:29:08 - INFO - __main__ -   validation loss: 55.429252, epoch: 2
05/15/2021 02:29:09 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:29:09 - INFO - __main__ -     Num examples = 150
05/15/2021 02:29:09 - INFO - __main__ -     Batch size = 8
05/15/2021 02:29:40 - INFO - __main__ -   validation loss: 65.282131, epoch: 3
05/15/2021 02:29:41 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:29:41 - INFO - __main__ -     Num examples = 150
05/15/2021 02:29:41 - INFO - __main__ -     Batch size = 8
05/15/2021 02:30:11 - INFO - __main__ -   validation loss: 74.497705, epoch: 4
05/15/2021 02:30:12 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:30:12 - INFO - __main__ -     Num examples = 150
05/15/2021 02:30:12 - INFO - __main__ -     Batch size = 8
05/15/2021 02:30:16 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:30:16 - INFO - __main__ -     Num examples = 800
05/15/2021 02:30:16 - INFO - __main__ -     Batch size = 8
05/15/2021 02:31:18 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:31:18 - INFO - __main__ -     Num examples = 150
05/15/2021 02:31:18 - INFO - __main__ -     Batch size = 4
05/15/2021 02:31:18 - INFO - __main__ -     Num steps = 148
05/15/2021 02:31:18 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:31:18 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:31:18 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:31:18 - INFO - __main__ -     Batch size = 4
05/15/2021 02:31:53 - INFO - __main__ -   validation loss: 59.505320, epoch: 1
05/15/2021 02:31:54 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:31:54 - INFO - __main__ -     Num examples = 150
05/15/2021 02:31:54 - INFO - __main__ -     Batch size = 8
05/15/2021 02:32:25 - INFO - __main__ -   validation loss: 55.429252, epoch: 2
05/15/2021 02:32:26 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:32:26 - INFO - __main__ -     Num examples = 150
05/15/2021 02:32:26 - INFO - __main__ -     Batch size = 8
05/15/2021 02:32:58 - INFO - __main__ -   validation loss: 65.282131, epoch: 3
05/15/2021 02:32:59 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:32:59 - INFO - __main__ -     Num examples = 150
05/15/2021 02:32:59 - INFO - __main__ -     Batch size = 8
05/15/2021 02:33:32 - INFO - __main__ -   validation loss: 74.497705, epoch: 4
05/15/2021 02:33:33 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:33:33 - INFO - __main__ -     Num examples = 150
05/15/2021 02:33:33 - INFO - __main__ -     Batch size = 8
05/15/2021 02:33:37 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:33:37 - INFO - __main__ -     Num examples = 800
05/15/2021 02:33:37 - INFO - __main__ -     Batch size = 8
05/15/2021 02:34:27 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:34:27 - INFO - __main__ -     Num examples = 150
05/15/2021 02:34:27 - INFO - __main__ -     Batch size = 4
05/15/2021 02:34:27 - INFO - __main__ -     Num steps = 148
05/15/2021 02:34:27 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:34:27 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:34:27 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:34:27 - INFO - __main__ -     Batch size = 4
05/15/2021 02:34:59 - INFO - __main__ -   validation loss: 59.505320, epoch: 1
05/15/2021 02:35:01 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:35:01 - INFO - __main__ -     Num examples = 150
05/15/2021 02:35:01 - INFO - __main__ -     Batch size = 8
05/15/2021 02:35:32 - INFO - __main__ -   validation loss: 55.429252, epoch: 2
05/15/2021 02:35:33 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:35:33 - INFO - __main__ -     Num examples = 150
05/15/2021 02:35:33 - INFO - __main__ -     Batch size = 8
05/15/2021 02:36:04 - INFO - __main__ -   validation loss: 65.282131, epoch: 3
05/15/2021 02:36:05 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:36:05 - INFO - __main__ -     Num examples = 150
05/15/2021 02:36:05 - INFO - __main__ -     Batch size = 8
05/15/2021 02:36:36 - INFO - __main__ -   validation loss: 74.497705, epoch: 4
05/15/2021 02:36:37 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:36:37 - INFO - __main__ -     Num examples = 150
05/15/2021 02:36:37 - INFO - __main__ -     Batch size = 8
05/15/2021 02:36:41 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:36:41 - INFO - __main__ -     Num examples = 800
05/15/2021 02:36:41 - INFO - __main__ -     Batch size = 8
05/15/2021 02:37:28 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:37:28 - INFO - __main__ -     Num examples = 150
05/15/2021 02:37:28 - INFO - __main__ -     Batch size = 4
05/15/2021 02:37:28 - INFO - __main__ -     Num steps = 148
05/15/2021 02:37:28 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:37:28 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:37:28 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:37:28 - INFO - __main__ -     Batch size = 4
05/15/2021 02:38:06 - INFO - __main__ -   validation loss: 53.493927, epoch: 1
05/15/2021 02:38:08 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:38:08 - INFO - __main__ -     Num examples = 150
05/15/2021 02:38:08 - INFO - __main__ -     Batch size = 8
05/15/2021 02:38:43 - INFO - __main__ -   validation loss: 45.279222, epoch: 2
05/15/2021 02:38:45 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:38:45 - INFO - __main__ -     Num examples = 150
05/15/2021 02:38:45 - INFO - __main__ -     Batch size = 8
05/15/2021 02:39:21 - INFO - __main__ -   validation loss: 79.471870, epoch: 3
05/15/2021 02:39:23 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:39:23 - INFO - __main__ -     Num examples = 150
05/15/2021 02:39:23 - INFO - __main__ -     Batch size = 8
05/15/2021 02:39:58 - INFO - __main__ -   validation loss: 82.727412, epoch: 4
05/15/2021 02:39:59 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:39:59 - INFO - __main__ -     Num examples = 150
05/15/2021 02:39:59 - INFO - __main__ -     Batch size = 8
05/15/2021 02:40:07 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:40:07 - INFO - __main__ -     Num examples = 800
05/15/2021 02:40:07 - INFO - __main__ -     Batch size = 8
05/15/2021 02:40:59 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:41:00 - INFO - __main__ -     Num examples = 150
05/15/2021 02:41:00 - INFO - __main__ -     Batch size = 4
05/15/2021 02:41:00 - INFO - __main__ -     Num steps = 148
05/15/2021 02:41:00 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:41:00 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:41:00 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:41:00 - INFO - __main__ -     Batch size = 4
05/15/2021 02:41:00 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/15/2021 02:41:00 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/15/2021 02:41:02 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/15/2021 02:41:02 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/15/2021 02:41:13 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:41:13 - INFO - __main__ -     Num examples = 150
05/15/2021 02:41:13 - INFO - __main__ -     Batch size = 4
05/15/2021 02:41:13 - INFO - __main__ -     Num steps = 148
05/15/2021 02:41:13 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:41:13 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:41:13 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:41:13 - INFO - __main__ -     Batch size = 4
05/15/2021 02:41:13 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/15/2021 02:41:13 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/15/2021 02:41:15 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/15/2021 02:41:15 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/15/2021 02:41:49 - INFO - __main__ -   validation loss: 69.646373, epoch: 1
05/15/2021 02:41:50 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:41:50 - INFO - __main__ -     Num examples = 150
05/15/2021 02:41:50 - INFO - __main__ -     Batch size = 8
05/15/2021 02:42:25 - INFO - __main__ -   validation loss: 57.629924, epoch: 2
05/15/2021 02:42:26 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:42:26 - INFO - __main__ -     Num examples = 150
05/15/2021 02:42:26 - INFO - __main__ -     Batch size = 8
05/15/2021 02:43:00 - INFO - __main__ -   validation loss: 57.916060, epoch: 3
05/15/2021 02:43:02 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:43:02 - INFO - __main__ -     Num examples = 150
05/15/2021 02:43:02 - INFO - __main__ -     Batch size = 8
05/15/2021 02:43:28 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 02:43:28 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 02:43:29 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 02:43:36 - INFO - __main__ -   validation loss: 58.236596, epoch: 4
05/15/2021 02:43:37 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:43:37 - INFO - __main__ -     Num examples = 150
05/15/2021 02:43:37 - INFO - __main__ -     Batch size = 8
05/15/2021 02:43:41 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:43:41 - INFO - __main__ -     Num examples = 800
05/15/2021 02:43:41 - INFO - __main__ -     Batch size = 8
05/15/2021 02:44:24 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:44:24 - INFO - __main__ -     Num examples = 150
05/15/2021 02:44:24 - INFO - __main__ -     Batch size = 4
05/15/2021 02:44:24 - INFO - __main__ -     Num steps = 148
05/15/2021 02:44:24 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:44:24 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:44:24 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:44:24 - INFO - __main__ -     Batch size = 4
05/15/2021 02:44:24 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/15/2021 02:44:24 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/15/2021 02:44:26 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/15/2021 02:44:26 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/15/2021 02:44:59 - INFO - __main__ -   validation loss: 65.774300, epoch: 1
05/15/2021 02:45:00 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:45:00 - INFO - __main__ -     Num examples = 150
05/15/2021 02:45:00 - INFO - __main__ -     Batch size = 8
05/15/2021 02:45:35 - INFO - __main__ -   validation loss: 44.994478, epoch: 2
05/15/2021 02:45:36 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:45:36 - INFO - __main__ -     Num examples = 150
05/15/2021 02:45:36 - INFO - __main__ -     Batch size = 8
05/15/2021 02:46:11 - INFO - __main__ -   validation loss: 60.457560, epoch: 3
05/15/2021 02:46:12 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:46:12 - INFO - __main__ -     Num examples = 150
05/15/2021 02:46:12 - INFO - __main__ -     Batch size = 8
05/15/2021 02:46:39 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 02:46:40 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 02:46:40 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 02:46:47 - INFO - __main__ -   validation loss: 59.454106, epoch: 4
05/15/2021 02:46:48 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:46:48 - INFO - __main__ -     Num examples = 150
05/15/2021 02:46:48 - INFO - __main__ -     Batch size = 8
05/15/2021 02:46:52 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:46:52 - INFO - __main__ -     Num examples = 800
05/15/2021 02:46:52 - INFO - __main__ -     Batch size = 8
05/15/2021 02:47:40 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:47:40 - INFO - __main__ -     Num examples = 150
05/15/2021 02:47:40 - INFO - __main__ -     Batch size = 4
05/15/2021 02:47:40 - INFO - __main__ -     Num steps = 148
05/15/2021 02:47:40 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:47:40 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:47:40 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:47:40 - INFO - __main__ -     Batch size = 4
05/15/2021 02:47:40 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/15/2021 02:47:40 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/15/2021 02:47:42 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/15/2021 02:47:42 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/15/2021 02:48:16 - INFO - __main__ -   validation loss: 69.646373, epoch: 1
05/15/2021 02:48:18 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:48:18 - INFO - __main__ -     Num examples = 150
05/15/2021 02:48:18 - INFO - __main__ -     Batch size = 8
05/15/2021 02:48:53 - INFO - __main__ -   validation loss: 57.629924, epoch: 2
05/15/2021 02:48:55 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:48:55 - INFO - __main__ -     Num examples = 150
05/15/2021 02:48:55 - INFO - __main__ -     Batch size = 8
05/15/2021 02:49:30 - INFO - __main__ -   validation loss: 57.916060, epoch: 3
05/15/2021 02:49:31 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:49:31 - INFO - __main__ -     Num examples = 150
05/15/2021 02:49:31 - INFO - __main__ -     Batch size = 8
05/15/2021 02:49:59 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 02:49:59 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 02:50:00 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 02:50:07 - INFO - __main__ -   validation loss: 58.236596, epoch: 4
05/15/2021 02:50:08 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:50:08 - INFO - __main__ -     Num examples = 150
05/15/2021 02:50:08 - INFO - __main__ -     Batch size = 8
05/15/2021 02:50:14 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:50:14 - INFO - __main__ -     Num examples = 800
05/15/2021 02:50:14 - INFO - __main__ -     Batch size = 8
05/15/2021 02:51:20 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:51:20 - INFO - __main__ -     Num examples = 150
05/15/2021 02:51:20 - INFO - __main__ -     Batch size = 4
05/15/2021 02:51:20 - INFO - __main__ -     Num steps = 148
05/15/2021 02:51:20 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:51:20 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:51:20 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:51:20 - INFO - __main__ -     Batch size = 4
05/15/2021 02:51:20 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/15/2021 02:51:20 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/15/2021 02:51:22 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/15/2021 02:51:22 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/15/2021 02:51:56 - INFO - __main__ -   validation loss: 65.774300, epoch: 1
05/15/2021 02:51:57 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:51:57 - INFO - __main__ -     Num examples = 150
05/15/2021 02:51:57 - INFO - __main__ -     Batch size = 8
05/15/2021 02:52:31 - INFO - __main__ -   validation loss: 44.994478, epoch: 2
05/15/2021 02:52:33 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:52:33 - INFO - __main__ -     Num examples = 150
05/15/2021 02:52:33 - INFO - __main__ -     Batch size = 8
05/15/2021 02:53:08 - INFO - __main__ -   validation loss: 60.457560, epoch: 3
05/15/2021 02:53:09 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:53:09 - INFO - __main__ -     Num examples = 150
05/15/2021 02:53:09 - INFO - __main__ -     Batch size = 8
05/15/2021 02:53:35 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 02:53:36 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 02:53:36 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 02:53:43 - INFO - __main__ -   validation loss: 59.454106, epoch: 4
05/15/2021 02:53:44 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:53:44 - INFO - __main__ -     Num examples = 150
05/15/2021 02:53:44 - INFO - __main__ -     Batch size = 8
05/15/2021 02:53:48 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:53:48 - INFO - __main__ -     Num examples = 800
05/15/2021 02:53:48 - INFO - __main__ -     Batch size = 8
05/15/2021 02:54:36 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:54:36 - INFO - __main__ -     Num examples = 150
05/15/2021 02:54:36 - INFO - __main__ -     Batch size = 4
05/15/2021 02:54:36 - INFO - __main__ -     Num steps = 148
05/15/2021 02:54:36 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:54:36 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:54:36 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:54:36 - INFO - __main__ -     Batch size = 4
05/15/2021 02:54:36 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/15/2021 02:54:36 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/15/2021 02:54:38 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/15/2021 02:54:38 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/15/2021 02:55:12 - INFO - __main__ -   validation loss: 65.774300, epoch: 1
05/15/2021 02:55:13 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:55:13 - INFO - __main__ -     Num examples = 150
05/15/2021 02:55:13 - INFO - __main__ -     Batch size = 8
05/15/2021 02:55:46 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:55:46 - INFO - __main__ -     Num examples = 150
05/15/2021 02:55:46 - INFO - __main__ -     Batch size = 4
05/15/2021 02:55:46 - INFO - __main__ -     Num steps = 148
05/15/2021 02:55:46 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:55:46 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:55:46 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:55:46 - INFO - __main__ -     Batch size = 4
05/15/2021 02:56:20 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:56:20 - INFO - __main__ -     Num examples = 150
05/15/2021 02:56:20 - INFO - __main__ -     Batch size = 4
05/15/2021 02:56:20 - INFO - __main__ -     Num steps = 148
05/15/2021 02:56:20 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:56:20 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:56:20 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:56:20 - INFO - __main__ -     Batch size = 4
05/15/2021 02:56:52 - INFO - __main__ -   validation loss: 59.505320, epoch: 1
05/15/2021 02:56:53 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:56:53 - INFO - __main__ -     Num examples = 150
05/15/2021 02:56:53 - INFO - __main__ -     Batch size = 8
05/15/2021 02:57:23 - INFO - __main__ -   validation loss: 55.429252, epoch: 2
05/15/2021 02:57:24 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:57:24 - INFO - __main__ -     Num examples = 150
05/15/2021 02:57:24 - INFO - __main__ -     Batch size = 8
05/15/2021 02:57:55 - INFO - __main__ -   validation loss: 65.282131, epoch: 3
05/15/2021 02:57:56 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:57:56 - INFO - __main__ -     Num examples = 150
05/15/2021 02:57:56 - INFO - __main__ -     Batch size = 8
05/15/2021 02:58:27 - INFO - __main__ -   validation loss: 74.497705, epoch: 4
05/15/2021 02:58:28 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:58:28 - INFO - __main__ -     Num examples = 150
05/15/2021 02:58:28 - INFO - __main__ -     Batch size = 8
05/15/2021 02:58:32 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:58:32 - INFO - __main__ -     Num examples = 800
05/15/2021 02:58:32 - INFO - __main__ -     Batch size = 8
05/15/2021 02:59:07 - INFO - __main__ -   ***** Running training *****
05/15/2021 02:59:07 - INFO - __main__ -     Num examples = 150
05/15/2021 02:59:07 - INFO - __main__ -     Batch size = 4
05/15/2021 02:59:07 - INFO - __main__ -     Num steps = 148
05/15/2021 02:59:07 - INFO - __main__ -   ***** Running validations *****
05/15/2021 02:59:07 - INFO - __main__ -     Num orig examples = 150
05/15/2021 02:59:07 - INFO - __main__ -     Num split examples = 150
05/15/2021 02:59:07 - INFO - __main__ -     Batch size = 4
05/15/2021 02:59:39 - INFO - __main__ -   validation loss: 62.501895, epoch: 1
05/15/2021 02:59:40 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 02:59:40 - INFO - __main__ -     Num examples = 150
05/15/2021 02:59:40 - INFO - __main__ -     Batch size = 8
05/15/2021 03:00:10 - INFO - __main__ -   validation loss: 50.764930, epoch: 2
05/15/2021 03:00:11 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:00:11 - INFO - __main__ -     Num examples = 150
05/15/2021 03:00:11 - INFO - __main__ -     Batch size = 8
05/15/2021 03:00:41 - INFO - __main__ -   validation loss: 57.989985, epoch: 3
05/15/2021 03:00:42 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:00:42 - INFO - __main__ -     Num examples = 150
05/15/2021 03:00:42 - INFO - __main__ -     Batch size = 8
05/15/2021 03:01:12 - INFO - __main__ -   validation loss: 72.910727, epoch: 4
05/15/2021 03:01:13 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:01:13 - INFO - __main__ -     Num examples = 150
05/15/2021 03:01:13 - INFO - __main__ -     Batch size = 8
05/15/2021 03:01:17 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:01:17 - INFO - __main__ -     Num examples = 800
05/15/2021 03:01:17 - INFO - __main__ -     Batch size = 8
05/15/2021 03:02:26 - INFO - __main__ -   ***** Running training *****
05/15/2021 03:02:26 - INFO - __main__ -     Num examples = 150
05/15/2021 03:02:26 - INFO - __main__ -     Batch size = 4
05/15/2021 03:02:26 - INFO - __main__ -     Num steps = 148
05/15/2021 03:02:26 - INFO - __main__ -   ***** Running validations *****
05/15/2021 03:02:26 - INFO - __main__ -     Num orig examples = 150
05/15/2021 03:02:26 - INFO - __main__ -     Num split examples = 150
05/15/2021 03:02:26 - INFO - __main__ -     Batch size = 4
05/15/2021 03:03:02 - INFO - __main__ -   validation loss: 53.942076, epoch: 1
05/15/2021 03:03:03 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:03:03 - INFO - __main__ -     Num examples = 150
05/15/2021 03:03:03 - INFO - __main__ -     Batch size = 8
05/15/2021 03:03:37 - INFO - __main__ -   validation loss: 46.418810, epoch: 2
05/15/2021 03:03:38 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:03:38 - INFO - __main__ -     Num examples = 150
05/15/2021 03:03:38 - INFO - __main__ -     Batch size = 8
05/15/2021 03:04:11 - INFO - __main__ -   validation loss: 83.428585, epoch: 3
05/15/2021 03:04:12 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:04:12 - INFO - __main__ -     Num examples = 150
05/15/2021 03:04:12 - INFO - __main__ -     Batch size = 8
05/15/2021 03:04:44 - INFO - __main__ -   validation loss: 92.128169, epoch: 4
05/15/2021 03:04:46 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:04:46 - INFO - __main__ -     Num examples = 150
05/15/2021 03:04:46 - INFO - __main__ -     Batch size = 8
05/15/2021 03:04:52 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:04:52 - INFO - __main__ -     Num examples = 800
05/15/2021 03:04:52 - INFO - __main__ -     Batch size = 8
05/15/2021 03:05:33 - INFO - __main__ -   ***** Running training *****
05/15/2021 03:05:33 - INFO - __main__ -     Num examples = 150
05/15/2021 03:05:33 - INFO - __main__ -     Batch size = 4
05/15/2021 03:05:33 - INFO - __main__ -     Num steps = 148
05/15/2021 03:05:33 - INFO - __main__ -   ***** Running validations *****
05/15/2021 03:05:33 - INFO - __main__ -     Num orig examples = 150
05/15/2021 03:05:33 - INFO - __main__ -     Num split examples = 150
05/15/2021 03:05:33 - INFO - __main__ -     Batch size = 4
05/15/2021 03:06:07 - INFO - __main__ -   validation loss: 41.542546, epoch: 1
05/15/2021 03:06:09 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:06:09 - INFO - __main__ -     Num examples = 150
05/15/2021 03:06:09 - INFO - __main__ -     Batch size = 8
05/15/2021 03:06:45 - INFO - __main__ -   validation loss: 57.261204, epoch: 2
05/15/2021 03:06:47 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:06:47 - INFO - __main__ -     Num examples = 150
05/15/2021 03:06:47 - INFO - __main__ -     Batch size = 8
05/15/2021 03:07:21 - INFO - __main__ -   validation loss: 59.993338, epoch: 3
05/15/2021 03:07:24 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:07:24 - INFO - __main__ -     Num examples = 150
05/15/2021 03:07:24 - INFO - __main__ -     Batch size = 8
05/15/2021 03:07:58 - INFO - __main__ -   validation loss: 62.623767, epoch: 4
05/15/2021 03:08:03 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:08:03 - INFO - __main__ -     Num examples = 150
05/15/2021 03:08:03 - INFO - __main__ -     Batch size = 8
05/15/2021 03:08:12 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:08:12 - INFO - __main__ -     Num examples = 800
05/15/2021 03:08:12 - INFO - __main__ -     Batch size = 8
05/15/2021 03:10:50 - INFO - __main__ -   ***** Running training *****
05/15/2021 03:10:50 - INFO - __main__ -     Num examples = 150
05/15/2021 03:10:50 - INFO - __main__ -     Batch size = 4
05/15/2021 03:10:50 - INFO - __main__ -     Num steps = 148
05/15/2021 03:10:50 - INFO - __main__ -   ***** Running validations *****
05/15/2021 03:10:50 - INFO - __main__ -     Num orig examples = 150
05/15/2021 03:10:50 - INFO - __main__ -     Num split examples = 150
05/15/2021 03:10:50 - INFO - __main__ -     Batch size = 4
05/15/2021 03:11:24 - INFO - __main__ -   validation loss: 65.548081, epoch: 1
05/15/2021 03:11:26 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:11:26 - INFO - __main__ -     Num examples = 150
05/15/2021 03:11:26 - INFO - __main__ -     Batch size = 8
05/15/2021 03:11:59 - INFO - __main__ -   validation loss: 51.811633, epoch: 2
05/15/2021 03:12:00 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:12:00 - INFO - __main__ -     Num examples = 150
05/15/2021 03:12:00 - INFO - __main__ -     Batch size = 8
05/15/2021 03:12:32 - INFO - __main__ -   validation loss: 70.029709, epoch: 3
05/15/2021 03:12:33 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:12:33 - INFO - __main__ -     Num examples = 150
05/15/2021 03:12:33 - INFO - __main__ -     Batch size = 8
05/15/2021 03:13:05 - INFO - __main__ -   validation loss: 87.166553, epoch: 4
05/15/2021 03:13:06 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:13:06 - INFO - __main__ -     Num examples = 150
05/15/2021 03:13:06 - INFO - __main__ -     Batch size = 8
05/15/2021 03:13:10 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:13:10 - INFO - __main__ -     Num examples = 800
05/15/2021 03:13:10 - INFO - __main__ -     Batch size = 8
05/15/2021 03:14:37 - INFO - __main__ -   ***** Running training *****
05/15/2021 03:14:37 - INFO - __main__ -     Num examples = 150
05/15/2021 03:14:37 - INFO - __main__ -     Batch size = 4
05/15/2021 03:14:37 - INFO - __main__ -     Num steps = 148
05/15/2021 03:14:37 - INFO - __main__ -   ***** Running validations *****
05/15/2021 03:14:37 - INFO - __main__ -     Num orig examples = 150
05/15/2021 03:14:37 - INFO - __main__ -     Num split examples = 150
05/15/2021 03:14:37 - INFO - __main__ -     Batch size = 4
05/15/2021 03:15:13 - INFO - __main__ -   validation loss: 59.505320, epoch: 1
05/15/2021 03:15:14 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:15:14 - INFO - __main__ -     Num examples = 150
05/15/2021 03:15:14 - INFO - __main__ -     Batch size = 8
05/15/2021 03:15:44 - INFO - __main__ -   validation loss: 55.429252, epoch: 2
05/15/2021 03:15:45 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:15:45 - INFO - __main__ -     Num examples = 150
05/15/2021 03:15:45 - INFO - __main__ -     Batch size = 8
05/15/2021 03:16:15 - INFO - __main__ -   validation loss: 65.282131, epoch: 3
05/15/2021 03:16:16 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:16:16 - INFO - __main__ -     Num examples = 150
05/15/2021 03:16:16 - INFO - __main__ -     Batch size = 8
05/15/2021 03:16:46 - INFO - __main__ -   validation loss: 74.497705, epoch: 4
05/15/2021 03:16:47 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:16:47 - INFO - __main__ -     Num examples = 150
05/15/2021 03:16:47 - INFO - __main__ -     Batch size = 8
05/15/2021 03:16:51 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:16:51 - INFO - __main__ -     Num examples = 800
05/15/2021 03:16:51 - INFO - __main__ -     Batch size = 8
05/15/2021 03:22:09 - INFO - __main__ -   ***** Running training *****
05/15/2021 03:22:09 - INFO - __main__ -     Num examples = 150
05/15/2021 03:22:09 - INFO - __main__ -     Batch size = 4
05/15/2021 03:22:09 - INFO - __main__ -     Num steps = 148
05/15/2021 03:22:09 - INFO - __main__ -   ***** Running validations *****
05/15/2021 03:22:09 - INFO - __main__ -     Num orig examples = 150
05/15/2021 03:22:09 - INFO - __main__ -     Num split examples = 150
05/15/2021 03:22:09 - INFO - __main__ -     Batch size = 4
05/15/2021 03:22:47 - INFO - __main__ -   validation loss: 41.542546, epoch: 1
05/15/2021 03:22:48 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:22:48 - INFO - __main__ -     Num examples = 150
05/15/2021 03:22:48 - INFO - __main__ -     Batch size = 8
05/15/2021 03:23:24 - INFO - __main__ -   validation loss: 57.261204, epoch: 2
05/15/2021 03:23:25 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:23:25 - INFO - __main__ -     Num examples = 150
05/15/2021 03:23:25 - INFO - __main__ -     Batch size = 8
05/15/2021 03:24:00 - INFO - __main__ -   validation loss: 59.993338, epoch: 3
05/15/2021 03:24:02 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:24:02 - INFO - __main__ -     Num examples = 150
05/15/2021 03:24:02 - INFO - __main__ -     Batch size = 8
05/15/2021 03:24:36 - INFO - __main__ -   validation loss: 62.623767, epoch: 4
05/15/2021 03:24:37 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:24:37 - INFO - __main__ -     Num examples = 150
05/15/2021 03:24:37 - INFO - __main__ -     Batch size = 8
05/15/2021 03:24:42 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:24:42 - INFO - __main__ -     Num examples = 800
05/15/2021 03:24:42 - INFO - __main__ -     Batch size = 8
05/15/2021 03:34:43 - INFO - __main__ -   ***** Running training *****
05/15/2021 03:34:43 - INFO - __main__ -     Num examples = 150
05/15/2021 03:34:43 - INFO - __main__ -     Batch size = 4
05/15/2021 03:34:43 - INFO - __main__ -     Num steps = 148
05/15/2021 03:34:43 - INFO - __main__ -   ***** Running validations *****
05/15/2021 03:34:43 - INFO - __main__ -     Num orig examples = 150
05/15/2021 03:34:43 - INFO - __main__ -     Num split examples = 150
05/15/2021 03:34:43 - INFO - __main__ -     Batch size = 4
05/15/2021 03:34:43 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/15/2021 03:34:43 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/15/2021 03:34:45 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/15/2021 03:34:45 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/15/2021 03:36:05 - INFO - __main__ -   ***** Running training *****
05/15/2021 03:36:05 - INFO - __main__ -     Num examples = 150
05/15/2021 03:36:05 - INFO - __main__ -     Batch size = 4
05/15/2021 03:36:05 - INFO - __main__ -     Num steps = 148
05/15/2021 03:36:05 - INFO - __main__ -   ***** Running validations *****
05/15/2021 03:36:05 - INFO - __main__ -     Num orig examples = 150
05/15/2021 03:36:05 - INFO - __main__ -     Num split examples = 150
05/15/2021 03:36:05 - INFO - __main__ -     Batch size = 4
05/15/2021 03:36:05 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/15/2021 03:36:05 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/15/2021 03:36:08 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/15/2021 03:36:08 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/15/2021 03:36:50 - INFO - __main__ -   validation loss: 47.174596, epoch: 1
05/15/2021 03:36:52 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:36:52 - INFO - __main__ -     Num examples = 150
05/15/2021 03:36:52 - INFO - __main__ -     Batch size = 8
05/15/2021 03:37:34 - INFO - __main__ -   validation loss: 53.224890, epoch: 2
05/15/2021 03:37:36 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:37:36 - INFO - __main__ -     Num examples = 150
05/15/2021 03:37:36 - INFO - __main__ -     Batch size = 8
05/15/2021 03:38:15 - INFO - __main__ -   validation loss: 53.311447, epoch: 3
05/15/2021 03:38:17 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:38:17 - INFO - __main__ -     Num examples = 150
05/15/2021 03:38:17 - INFO - __main__ -     Batch size = 8
05/15/2021 03:38:49 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 03:38:49 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 03:38:50 - WARNING - optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
05/15/2021 03:38:58 - INFO - __main__ -   validation loss: 54.168640, epoch: 4
05/15/2021 03:38:59 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:38:59 - INFO - __main__ -     Num examples = 150
05/15/2021 03:38:59 - INFO - __main__ -     Batch size = 8
05/15/2021 03:39:04 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:39:04 - INFO - __main__ -     Num examples = 800
05/15/2021 03:39:04 - INFO - __main__ -     Batch size = 8
05/15/2021 03:45:02 - INFO - __main__ -   ***** Running training *****
05/15/2021 03:45:02 - INFO - __main__ -     Num examples = 150
05/15/2021 03:45:02 - INFO - __main__ -     Batch size = 4
05/15/2021 03:45:02 - INFO - __main__ -     Num steps = 148
05/15/2021 03:45:02 - INFO - __main__ -   ***** Running validations *****
05/15/2021 03:45:02 - INFO - __main__ -     Num orig examples = 150
05/15/2021 03:45:02 - INFO - __main__ -     Num split examples = 150
05/15/2021 03:45:02 - INFO - __main__ -     Batch size = 4
05/15/2021 03:45:02 - INFO - modeling -   loading archive file pt_model/laptop_pt/
05/15/2021 03:45:02 - INFO - modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

05/15/2021 03:45:04 - INFO - modeling -   Weights of BertForABSA not initialized from pretrained model: ['groie.pre_layers.0.attention.self.query.weight', 'groie.pre_layers.0.attention.self.query.bias', 'groie.pre_layers.0.attention.self.key.weight', 'groie.pre_layers.0.attention.self.key.bias', 'groie.pre_layers.0.attention.self.value.weight', 'groie.pre_layers.0.attention.self.value.bias', 'groie.pre_layers.0.attention.output.dense.weight', 'groie.pre_layers.0.attention.output.dense.bias', 'groie.pre_layers.0.attention.output.LayerNorm.weight', 'groie.pre_layers.0.attention.output.LayerNorm.bias', 'groie.pre_layers.0.intermediate.dense.weight', 'groie.pre_layers.0.intermediate.dense.bias', 'groie.pre_layers.0.output.dense.weight', 'groie.pre_layers.0.output.dense.bias', 'groie.pre_layers.0.output.LayerNorm.weight', 'groie.pre_layers.0.output.LayerNorm.bias', 'groie.pre_layers.1.attention.self.query.weight', 'groie.pre_layers.1.attention.self.query.bias', 'groie.pre_layers.1.attention.self.key.weight', 'groie.pre_layers.1.attention.self.key.bias', 'groie.pre_layers.1.attention.self.value.weight', 'groie.pre_layers.1.attention.self.value.bias', 'groie.pre_layers.1.attention.output.dense.weight', 'groie.pre_layers.1.attention.output.dense.bias', 'groie.pre_layers.1.attention.output.LayerNorm.weight', 'groie.pre_layers.1.attention.output.LayerNorm.bias', 'groie.pre_layers.1.intermediate.dense.weight', 'groie.pre_layers.1.intermediate.dense.bias', 'groie.pre_layers.1.output.dense.weight', 'groie.pre_layers.1.output.dense.bias', 'groie.pre_layers.1.output.LayerNorm.weight', 'groie.pre_layers.1.output.LayerNorm.bias', 'groie.pre_layers.2.attention.self.query.weight', 'groie.pre_layers.2.attention.self.query.bias', 'groie.pre_layers.2.attention.self.key.weight', 'groie.pre_layers.2.attention.self.key.bias', 'groie.pre_layers.2.attention.self.value.weight', 'groie.pre_layers.2.attention.self.value.bias', 'groie.pre_layers.2.attention.output.dense.weight', 'groie.pre_layers.2.attention.output.dense.bias', 'groie.pre_layers.2.attention.output.LayerNorm.weight', 'groie.pre_layers.2.attention.output.LayerNorm.bias', 'groie.pre_layers.2.intermediate.dense.weight', 'groie.pre_layers.2.intermediate.dense.bias', 'groie.pre_layers.2.output.dense.weight', 'groie.pre_layers.2.output.dense.bias', 'groie.pre_layers.2.output.LayerNorm.weight', 'groie.pre_layers.2.output.LayerNorm.bias', 'groie.pre_layers.3.attention.self.query.weight', 'groie.pre_layers.3.attention.self.query.bias', 'groie.pre_layers.3.attention.self.key.weight', 'groie.pre_layers.3.attention.self.key.bias', 'groie.pre_layers.3.attention.self.value.weight', 'groie.pre_layers.3.attention.self.value.bias', 'groie.pre_layers.3.attention.output.dense.weight', 'groie.pre_layers.3.attention.output.dense.bias', 'groie.pre_layers.3.attention.output.LayerNorm.weight', 'groie.pre_layers.3.attention.output.LayerNorm.bias', 'groie.pre_layers.3.intermediate.dense.weight', 'groie.pre_layers.3.intermediate.dense.bias', 'groie.pre_layers.3.output.dense.weight', 'groie.pre_layers.3.output.dense.bias', 'groie.pre_layers.3.output.LayerNorm.weight', 'groie.pre_layers.3.output.LayerNorm.bias', 'groie.crf_layers.0.start_transitions', 'groie.crf_layers.0.end_transitions', 'groie.crf_layers.0.transitions', 'groie.crf_layers.1.start_transitions', 'groie.crf_layers.1.end_transitions', 'groie.crf_layers.1.transitions', 'groie.crf_layers.2.start_transitions', 'groie.crf_layers.2.end_transitions', 'groie.crf_layers.2.transitions', 'groie.crf_layers.3.start_transitions', 'groie.crf_layers.3.end_transitions', 'groie.crf_layers.3.transitions', 'groie.classifier.weight', 'groie.classifier.bias']
05/15/2021 03:45:04 - INFO - modeling -   Weights from pretrained model not used in BertForABSA: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']
05/15/2021 03:45:40 - INFO - __main__ -   validation loss: 47.174596, epoch: 1
05/15/2021 03:45:43 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:45:43 - INFO - __main__ -     Num examples = 150
05/15/2021 03:45:43 - INFO - __main__ -     Batch size = 8
05/15/2021 03:45:52 - INFO - __main__ -   ***** Running training *****
05/15/2021 03:45:52 - INFO - __main__ -     Num examples = 150
05/15/2021 03:45:52 - INFO - __main__ -     Batch size = 4
05/15/2021 03:45:52 - INFO - __main__ -     Num steps = 148
05/15/2021 03:45:52 - INFO - __main__ -   ***** Running validations *****
05/15/2021 03:45:52 - INFO - __main__ -     Num orig examples = 150
05/15/2021 03:45:52 - INFO - __main__ -     Num split examples = 150
05/15/2021 03:45:52 - INFO - __main__ -     Batch size = 4
05/15/2021 03:48:05 - INFO - __main__ -   ***** Running training *****
05/15/2021 03:48:05 - INFO - __main__ -     Num examples = 150
05/15/2021 03:48:05 - INFO - __main__ -     Batch size = 4
05/15/2021 03:48:05 - INFO - __main__ -     Num steps = 148
05/15/2021 03:48:05 - INFO - __main__ -   ***** Running validations *****
05/15/2021 03:48:05 - INFO - __main__ -     Num orig examples = 150
05/15/2021 03:48:05 - INFO - __main__ -     Num split examples = 150
05/15/2021 03:48:05 - INFO - __main__ -     Batch size = 4
05/15/2021 03:48:45 - INFO - __main__ -   validation loss: 41.542546, epoch: 1
05/15/2021 03:48:47 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:48:47 - INFO - __main__ -     Num examples = 150
05/15/2021 03:48:47 - INFO - __main__ -     Batch size = 8
05/15/2021 03:49:21 - INFO - __main__ -   validation loss: 57.261204, epoch: 2
05/15/2021 03:49:23 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:49:23 - INFO - __main__ -     Num examples = 150
05/15/2021 03:49:23 - INFO - __main__ -     Batch size = 8
05/15/2021 03:50:03 - INFO - __main__ -   validation loss: 59.993338, epoch: 3
05/15/2021 03:50:05 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:50:05 - INFO - __main__ -     Num examples = 150
05/15/2021 03:50:05 - INFO - __main__ -     Batch size = 8
05/15/2021 03:50:42 - INFO - __main__ -   validation loss: 62.623767, epoch: 4
05/15/2021 03:50:44 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:50:44 - INFO - __main__ -     Num examples = 150
05/15/2021 03:50:44 - INFO - __main__ -     Batch size = 8
05/15/2021 03:50:51 - INFO - __main__ -   ***** Running evaluation *****
05/15/2021 03:50:51 - INFO - __main__ -     Num examples = 800
05/15/2021 03:50:51 - INFO - __main__ -     Batch size = 8
